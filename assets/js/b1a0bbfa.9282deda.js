"use strict";(self.webpackChunkcloud=self.webpackChunkcloud||[]).push([[2164],{3905:(e,n,a)=>{a.d(n,{Zo:()=>u,kt:()=>m});var t=a(7294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function s(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=t.createContext({}),d=function(e){var n=t.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):s(s({},n),e)),a},u=function(e){var n=d(e.components);return t.createElement(l.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},p=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),p=d(a),m=r,b=p["".concat(l,".").concat(m)]||p[m]||c[m]||i;return a?t.createElement(b,s(s({ref:n},u),{},{components:a})):t.createElement(b,s({ref:n},u))}));function m(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=a.length,s=new Array(i);s[0]=p;var o={};for(var l in n)hasOwnProperty.call(n,l)&&(o[l]=n[l]);o.originalType=e,o.mdxType="string"==typeof e?e:r,s[1]=o;for(var d=2;d<i;d++)s[d]=a[d];return t.createElement.apply(null,s)}return t.createElement.apply(null,a)}p.displayName="MDXCreateElement"},7999:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>d});var t=a(7462),r=(a(7294),a(3905));const i={},s="minikube",o={unversionedId:"minikube",id:"minikube",title:"minikube",description:"Minikube related hands-on notes",source:"@site/docs/minikube.md",sourceDirName:".",slug:"/minikube",permalink:"/cloud/docs/minikube",draft:!1,editUrl:"https://github.com/facebook/docusaurus/edit/main/website/docs/minikube.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Performance",permalink:"/cloud/docs/linux/linux_perf"},next:{title:"oc",permalink:"/cloud/docs/openshift/oc"}},l={},d=[{value:"Contents",id:"contents",level:2},{value:"My minikube environment",id:"my-minikube-environment",level:2},{value:"Windows",id:"windows",level:3},{value:"Operations",id:"operations",level:2},{value:"Connect to a host having minikube VM",id:"connect-to-a-host-having-minikube-vm",level:3},{value:"start minikube",id:"start-minikube",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Creating VM error",id:"creating-vm-error",level:3},{value:"Error",id:"error",level:4},{value:"Resolution",id:"resolution",level:4},{value:"bad certificate",id:"bad-certificate",level:3},{value:"Error",id:"error-1",level:4},{value:"Resolution",id:"resolution-1",level:4},{value:"Commands reference",id:"commands-reference",level:2},{value:"System Outlook",id:"system-outlook",level:2},{value:"Reference",id:"reference",level:2},{value:"Lab",id:"lab",level:2},{value:"02 Operating containers",id:"02-operating-containers",level:3},{value:"04 Running an Application",id:"04-running-an-application",level:3},{value:"Deleting pod/deployment",id:"deleting-poddeployment",level:4},{value:"pod without a default command",id:"pod-without-a-default-command",level:4},{value:"Naked pod : not managed by deployment",id:"naked-pod--not-managed-by-deployment",level:4},{value:"Lab 4. Running an Application in Kubernetes",id:"lab-4-running-an-application-in-kubernetes",level:4},{value:"05 Managing application",id:"05-managing-application",level:3},{value:"Labels",id:"labels",level:4},{value:"Running an application",id:"running-an-application",level:4},{value:"namespace",id:"namespace",level:4},{value:"managing scailability : num of replicas",id:"managing-scailability--num-of-replicas",level:4},{value:"Managing application updates and rollbacks",id:"managing-application-updates-and-rollbacks",level:4},{value:"Lab 05 Managing deployment",id:"lab-05-managing-deployment",level:4},{value:"06 Exposing applications (Networking)",id:"06-exposing-applications-networking",level:3},{value:"Expose a deployment",id:"expose-a-deployment",level:4},{value:"Scaling the deployment will add IP Endpoints as PODs increases.",id:"scaling-the-deployment-will-add-ip-endpoints-as-pods-increases",level:4},{value:"Using DNS in k8s.",id:"using-dns-in-k8s",level:4},{value:"nslookup",id:"nslookup",level:4},{value:"Ingress",id:"ingress",level:4},{value:"Lab 6 Exposing Pods",id:"lab-6-exposing-pods",level:4},{value:"07 Managing Pod Volumes",id:"07-managing-pod-volumes",level:3},{value:"Managing Pod Volumes",id:"managing-pod-volumes",level:4},{value:"Using persistent volumes",id:"using-persistent-volumes",level:4},{value:"Setting up Pods to use PVs",id:"setting-up-pods-to-use-pvs",level:4},{value:"Dynamic provisioning",id:"dynamic-provisioning",level:4},{value:"Using ConfigMaps",id:"using-configmaps",level:4},{value:"Using Secret",id:"using-secret",level:4},{value:"test2",id:"test2",level:2}],u={toc:d};function c(e){let{components:n,...a}=e;return(0,r.kt)("wrapper",(0,t.Z)({},u,a,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"minikube"},"minikube"),(0,r.kt)("p",null,"Minikube related hands-on notes       "),(0,r.kt)("h2",{id:"contents"},"Contents"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#minikube"},"minikube"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#contents"},"Contents")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#my-minikube-environment"},"My minikube environment"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#windows"},"Windows")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#operations"},"Operations"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#connect-to-a-host-having-minikube-vm"},"Connect to a host having minikube VM")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#start-minikube"},"start minikube")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#troubleshooting"},"Troubleshooting"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#creating-vm-error"},"Creating VM error"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#error"},"Error")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#resolution"},"Resolution")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#bad-certificate"},"bad certificate"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#error-1"},"Error")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#resolution-1"},"Resolution")))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#commands-reference"},"Commands reference")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#system-outlook"},"System Outlook")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#reference"},"Reference")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#lab"},"Lab"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#02-operating-containers"},"02 Operating containers")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#04-running-an-application"},"04 Running an Application"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#deleting-poddeployment"},"Deleting pod/deployment")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#pod-without-a-default-command"},"pod without a default command")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#naked-pod--not-managed-by-deployment"},"Naked pod : not managed by deployment")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#lab-4-running-an-application-in-kubernetes"},"Lab 4. Running an Application in Kubernetes")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#05-managing-application"},"05 Managing application"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#labels"},"Labels")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#running-an-application"},"Running an application")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#namespace"},"namespace")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#managing-scailability--num-of-replicas"},"managing scailability : num of replicas")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#managing-application-updates-and-rollbacks"},"Managing application updates and rollbacks")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#lab-05-managing-deployment"},"Lab 05 Managing deployment")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#06-exposing-applications-networking"},"06 Exposing applications (Networking)"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#expose-a-deployment"},"Expose a deployment")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#scaling-the-deployment-will-add-ip-endpoints-as-pods-increases"},"Scaling the deployment will add IP Endpoints as PODs increases.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#using-dns-in-k8s"},"Using DNS in k8s.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#nslookup"},"nslookup")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#ingress"},"Ingress")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#lab-6-exposing-pods"},"Lab 6 Exposing Pods")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#07-managing-pod-volumes"},"07 Managing Pod Volumes"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#managing-pod-volumes"},"Managing Pod Volumes")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#using-persistent-volumes"},"Using persistent volumes")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#setting-up-pods-to-use-pvs"},"Setting up Pods to use PVs")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#dynamic-provisioning"},"Dynamic provisioning")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#using-configmaps"},"Using ConfigMaps")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#using-secret"},"Using Secret")))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#test2"},"test2"))))),(0,r.kt)("h2",{id:"my-minikube-environment"},"My minikube environment"),(0,r.kt)("h3",{id:"windows"},"Windows"),(0,r.kt)("p",null,"On a ten years old Windows thinkpad laptop with 24 GB memory, ",(0,r.kt)("inlineCode",{parentName:"p"},"Fedora")," VMware VM.",(0,r.kt)("br",{parentName:"p"}),"\n","Starting ",(0,r.kt)("inlineCode",{parentName:"p"},"minikube")," by ",(0,r.kt)("inlineCode",{parentName:"p"},"KVM")," on the Fedora VM.     "),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"#Contents"},"Go to content")),(0,r.kt)("h2",{id:"operations"},"Operations"),(0,r.kt)("p",null,"My daily operations such as starting minikube etc.    "),(0,r.kt)("h3",{id:"connect-to-a-host-having-minikube-vm"},"Connect to a host having minikube VM"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"ssh junsulee@fedora # login to fedora VM\nsudo su -  # for operations needing root permission\n")),(0,r.kt)("h3",{id:"start-minikube"},"start minikube"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Give KVM authority to users. give ",(0,r.kt)("inlineCode",{parentName:"li"},"libvirt")," group to users.",(0,r.kt)("br",{parentName:"li"}),"Necessary to start ",(0,r.kt)("inlineCode",{parentName:"li"},"minikube")," ")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"# usermod -aG libvirt junsulee\n# usermod -aG libvirt student\n# grep vmx /proc/cpuinfo    ## should have `vmx` \n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Start by a non root user      ")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"minikube start --memory 4096 --vm-driver=kvm2\n")),(0,r.kt)("p",null,"example :  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'[junsulee@fedora ~]$ minikube start --memory 4096 --vm-driver=kvm2\n* minikube v1.20.0 on Fedora 34\n* Using the kvm2 driver based on user configuration\n* Starting control plane node minikube in cluster minikube\n* Creating kvm2 VM (CPUs=2, Memory=4096MB, Disk=20000MB) ...\n* Preparing Kubernetes v1.20.2 on Docker 20.10.6 ...\n  - Generating certificates and keys ...\n  - Booting up control plane ...\n  - Configuring RBAC rules ...\n* Verifying Kubernetes components...\n  - Using image gcr.io/k8s-minikube/storage-provisioner:v5\n* Enabled addons: default-storageclass, storage-provisioner\n* Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default\n')),(0,r.kt)("p",null,"When starting after system halt    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ minikube start --memory 4096 --vm-driver=kvm2\n* minikube v1.20.0 on Fedora 34\n* minikube 1.22.0 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.22.0\n* To disable this notice, run: \'minikube config set WantUpdateNotification false\'\n\n* Using the kvm2 driver based on existing profile\n* Starting control plane node minikube in cluster minikube\n* Restarting existing kvm2 VM for "minikube" ...\n* Preparing Kubernetes v1.20.2 on Docker 20.10.6 ...\nX Problems detected in kubelet:\n  Aug 29 23:38:41 minikube kubelet[2691]: E0829 23:38:41.239851    2691 pod_workers.go:191] Error syncing pod b320587ee357c92247809ba00ce3080a ("kube-apiserver-minikube_kube-system(b320587ee357c92247809ba00ce3080a)"), skipping: failed to "StartContainer" for "kube-apiserver" with CrashLoopBackOff: "back-off 20s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(b320587ee357c92247809ba00ce3080a)"\nX Problems detected in kubelet:\n  Aug 29 23:38:41 minikube kubelet[2691]: E0829 23:38:41.239851    2691 pod_workers.go:191] Error syncing pod b320587ee357c92247809ba00ce3080a ("kube-apiserver-minikube_kube-system(b320587ee357c92247809ba00ce3080a)"), skipping: failed to "StartContainer" for "kube-apiserver" with CrashLoopBackOff: "back-off 20s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(b320587ee357c92247809ba00ce3080a)"\n  Aug 29 23:38:50 minikube kubelet[2691]: E0829 23:38:50.122463    2691 pod_workers.go:191] Error syncing pod b320587ee357c92247809ba00ce3080a ("kube-apiserver-minikube_kube-system(b320587ee357c92247809ba00ce3080a)"), skipping: failed to "StartContainer" for "kube-apiserver" with CrashLoopBackOff: "back-off 20s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(b320587ee357c92247809ba00ce3080a)"\n  Aug 29 23:38:51 minikube kubelet[2691]: E0829 23:38:51.165528    2691 pod_workers.go:191] Error syncing pod 474c55dfb64741cc485e46b6bb9f2dc0 ("kube-controller-manager-minikube_kube-system(474c55dfb64741cc485e46b6bb9f2dc0)"), skipping: failed to "StartContainer" for "kube-controller-manager" with CrashLoopBackOff: "back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(474c55dfb64741cc485e46b6bb9f2dc0)"\n  Aug 29 23:38:54 minikube kubelet[2691]: E0829 23:38:54.439750    2691 pod_workers.go:191] Error syncing pod 474c55dfb64741cc485e46b6bb9f2dc0 ("kube-controller-manager-minikube_kube-system(474c55dfb64741cc485e46b6bb9f2dc0)"), skipping: failed to "StartContainer" for "kube-controller-manager" with CrashLoopBackOff: "back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(474c55dfb64741cc485e46b6bb9f2dc0)"\n! Unable to restart cluster, will reset it: apiserver health: apiserver healthz never reported healthy: cluster wait timed out during healthz check\n  - Generating certificates and keys ...\n  - Booting up control plane ...\n  - Configuring RBAC rules ...\n* Verifying Kubernetes components...\n  - Using image gcr.io/k8s-minikube/storage-provisioner:v5\n* Enabled addons: default-storageclass, storage-provisioner\n* Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default\n')),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"#Contents"},"Go to content")),(0,r.kt)("h2",{id:"troubleshooting"},"Troubleshooting"),(0,r.kt)("h3",{id:"creating-vm-error"},"Creating VM error"),(0,r.kt)("h4",{id:"error"},"Error"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"! StartHost failed, but will try again: creating host: create: Error creating machine: Error in driver during machine creation: error creating VM: virError(Code=1, Domain=10, Message='internal error: process exited while connecting to monitor: 2021-05-17T07:32:21.253962Z qemu-system-x86_64: error: failed to set MSR 0x48f to 0x7fffff00036dfb\nqemu-system-x86_64: ../target/i386/kvm.c:2701: kvm_buf_set_msrs: Assertion `ret == cpu->kvm_msr_buf->nmsrs' failed.')\n* Creating kvm2 VM (CPUs=2, Memory=4096MB, Disk=20000MB) ...\n")),(0,r.kt)("h4",{id:"resolution"},"Resolution"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/minikube/issues/2968"},"https://github.com/kubernetes/minikube/issues/2968"),"\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/minikube/issues/2412"},"https://github.com/kubernetes/minikube/issues/2412")),(0,r.kt)("p",null,"On vmware configuration, turn on 'Virtualize CPU performance counters'.     "),(0,r.kt)("h3",{id:"bad-certificate"},(0,r.kt)("a",{parentName:"h3",href:"https://stackoverflow.com/questions/71542604/minikube-remote-error-tls-bad-certificate"},"bad certificate")),(0,r.kt)("h4",{id:"error-1"},"Error"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ minikube_start\n\ud83d\ude04  minikube v1.20.0 on Fedora 34\n\u2728  Using the kvm2 driver based on existing profile\n\ud83d\udc4d  Starting control plane node minikube in cluster minikube\n\ud83d\udd04  Restarting existing kvm2 VM for "minikube" ...\n\ud83d\udc33  Preparing Kubernetes v1.20.2 on Docker 20.10.6 ...\n\u274c  Problems detected in etcd [4e630926db47]:\n    2022-05-21 04:49:16.015098 I | embed: rejected connection from "127.0.0.1:53760" (error "remote error: tls: bad certificate", ServerName "")\n    2022-05-21 04:49:19.119305 I | embed: rejected connection from "127.0.0.1:53766" (error "remote error: tls: bad certificate", ServerName "")\n    2022-05-21 04:49:20.231942 I | embed: rejected connection from "127.0.0.1:53774" (error "remote error: tls: bad certificate", ServerName "")\n')),(0,r.kt)("h4",{id:"resolution-1"},"Resolution"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"kubectl config view\nkubectl config delete-cluster minikube\nminikube delete\nminikube start --memory 4096 --vm-driver=kvm2\n")),(0,r.kt)("h2",{id:"commands-reference"},"Commands reference"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"minikube dashboard   ## works in fedora GUI. Opening web browser\n")),(0,r.kt)("h2",{id:"system-outlook"},"System Outlook"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl get all\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   17\n\n$ kubectl get nodes\nNAME       STATUS   ROLES                  AGE   VERSION\nminikube   Ready    control-plane,master   6d    v1.20.2\n\n$ kubectl cluster-info\nKubernetes control plane is running at https://192.168.39.235:8443\nKubeDNS is running at https://192.168.39.235:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n\n$ kubectl get all -A\nNAMESPACE              NAME                                            READY   STATUS    RESTARTS   AGE\ndefault                pod/cmd-nginx-57bb5f6747-hznc7                  1/1     Running   1          4d18h\ndefault                pod/cmd-nginx-57bb5f6747-kmkjr                  1/1     Running   1          4d17h\ndefault                pod/redis-6fb5b985bc-s6gpq                      1/1     Running   0          4d2h\nkube-system            pod/coredns-74ff55c5b-qgdjv                     1/1     Running   3          123d\nkube-system            pod/etcd-minikube                               1/1     Running   33         123d\nkube-system            pod/kube-apiserver-minikube                     1/1     Running   78         123d\nkube-system            pod/kube-controller-manager-minikube            1/1     Running   11         123d\nkube-system            pod/kube-proxy-x48k4                            1/1     Running   3          123d\nkube-system            pod/kube-scheduler-minikube                     1/1     Running   3          123d\nkube-system            pod/storage-provisioner                         1/1     Running   133        123d\nkubernetes-dashboard   pod/dashboard-metrics-scraper-f6647bd8c-7hgqz   1/1     Running   3          122d\nkubernetes-dashboard   pod/kubernetes-dashboard-968bcb79-lktd2         1/1     Running   69         122d\nmyspace                pod/busybox2                                    1/1     Running   337        88d\n\nNAMESPACE              NAME                                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE\ndefault                service/kubernetes                  ClusterIP   10.96.0.1        <none>        443/TCP                  123d\nkube-system            service/kube-dns                    ClusterIP   10.96.0.10       <none>        53/UDP,53/TCP,9153/TCP   123d\nkubernetes-dashboard   service/dashboard-metrics-scraper   ClusterIP   10.105.137.234   <none>        8000/TCP                 122d\nkubernetes-dashboard   service/kubernetes-dashboard        ClusterIP   10.101.187.187   <none>        80/TCP                   122d\n\nNAMESPACE     NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\nkube-system   daemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   123d\n\nNAMESPACE              NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\ndefault                deployment.apps/cmd-nginx                   1/1     1            1           4d18h\ndefault                deployment.apps/redis                       1/1     1            1           4d2h\nkube-system            deployment.apps/coredns                     1/1     1            1           123d\nkubernetes-dashboard   deployment.apps/dashboard-metrics-scraper   1/1     1            1           122d\nkubernetes-dashboard   deployment.apps/kubernetes-dashboard        1/1     1            1           122d\n\nNAMESPACE              NAME                                                  DESIRED   CURRENT   READY   AGE\ndefault                replicaset.apps/cmd-nginx-57bb5f6747                  1         1         1       4d18h\ndefault                replicaset.apps/redis-6fb5b985bc                      1         1         1       4d2h\nkube-system            replicaset.apps/coredns-74ff55c5b                     1         1         1       123d\nkubernetes-dashboard   replicaset.apps/dashboard-metrics-scraper-f6647bd8c   1         1         1       122d\nkubernetes-dashboard   replicaset.apps/kubernetes-dashboard-968bcb79         1         1         1       122d\n\n")),(0,r.kt)("p",null,"For further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.      "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl config view\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority: /home/junsulee/.minikube/ca.crt\n    extensions:\n    - extension:\n        last-update: Sat, 14 May 2022 13:01:44 AEST\n        provider: minikube.sigs.k8s.io\n        version: v1.20.0\n      name: cluster_info\n    server: https://192.168.39.235:8443\n  name: minikube\ncontexts:\n- context:\n    cluster: minikube\n    extensions:\n    - extension:\n        last-update: Sat, 14 May 2022 13:01:44 AEST\n        provider: minikube.sigs.k8s.io\n        version: v1.20.0\n      name: context_info\n    namespace: default\n    user: minikube\n  name: minikube\ncurrent-context: minikube\nkind: Config\npreferences: {}\nusers:\n- name: minikube\n  user:\n    client-certificate: /home/junsulee/.minikube/profiles/minikube/client.crt\n    client-key: /home/junsulee/.minikube/profiles/minikube/client.key\n")),(0,r.kt)("h2",{id:"reference"},"Reference"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/sandervanvugt/kubernetes"},"Oreilly kubernetes education github repository")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://borysneselovskyi.wordpress.com/2018/02/19/kvm-virtualization-on-top-of-the-vmware-workstation-12-guest-vms/"},"KVM Virtualization on VMware 12")),(0,r.kt)("h2",{id:"lab"},"Lab"),(0,r.kt)("h3",{id:"02-operating-containers"},"02 Operating containers"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ docker run --rm -v /dev/log:/dev/log fedora:latest logger \"Message from the container\" \nUnable to find image 'fedora:latest' locally\nlatest: Pulling from library/fedora\n70fb9965a23f: Pull complete \nDigest: sha256:0c18a515203b836ea840f7033a11d6833f9468fda6a99f5a29695cfbaf43f24a\nStatus: Downloaded newer image for fedora:latest\n\n$ journalctl |grep container\n...\nOct 03 20:40:39 fedora root[52426]: Message from the container\n")),(0,r.kt)("h3",{id:"04-running-an-application"},"04 Running an Application"),(0,r.kt)("h4",{id:"deleting-poddeployment"},"Deleting pod/deployment"),(0,r.kt)("p",null,"To start from scratch, check existing deployment/pod, then delete.        "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl get deployment\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   1/1     1            1           32d\n\n$ kubectl get pod\nNAME                         READY   STATUS    RESTARTS   AGE\ncmd-nginx-57bb5f6747-tv4sb   1/1     Running   0          31s\n")),(0,r.kt)("p",null,"At this time, the pod runs again with different name because of deployment.",(0,r.kt)("br",{parentName:"p"}),"\n","to clear, need to delete deployment together.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ kubectl delete deployment cmd-nginx\ndeployment.apps "cmd-nginx" deleted\n\n$ kubectl get deployment\nNo resources found in default namespace.\n\n$ kubectl get pod\nNAME                         READY   STATUS        RESTARTS   AGE\ncmd-nginx-57bb5f6747-tv4sb   0/1     Terminating   0          6m58s\n$ kubectl delete pod cmd-nginx-57bb5f6747-tv4sb\npod "cmd-nginx-57bb5f6747-tv4sb" deleted\n$ kubectl get pod\nNo resources found in default namespace.\n')),(0,r.kt)("h4",{id:"pod-without-a-default-command"},"pod without a default command"),(0,r.kt)("p",null,"Creating a pod that does not have a default command becomes abnormal status.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl create deployment my-dep --image=busybox\ndeployment.apps/my-dep created\n$ kubectl get pod\nNAME                      READY   STATUS              RESTARTS   AGE\nmy-dep-68d7dcffc4-fvzsp   0/1     ContainerCreating   0          10s\n$ date;kubectl get pod\nSat 17 Sep 2022 13:18:40 AEST\nNAME                      READY   STATUS      RESTARTS   AGE\nmy-dep-68d7dcffc4-fvzsp   0/1     Completed   0          22s\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ date;kubectl get pod\nSat 17 Sep 2022 13:18:48 AEST\nNAME                      READY   STATUS             RESTARTS   AGE\nmy-dep-68d7dcffc4-fvzsp   0/1     CrashLoopBackOff   1          30s\n")),(0,r.kt)("p",null,"Check the history.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"[junsulee@fedora kube]$ kubectl describe pod my-dep-68d7dcffc4-fvzsp\n..\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s       <======\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n..\n")),(0,r.kt)("h4",{id:"naked-pod--not-managed-by-deployment"},"Naked pod : not managed by deployment"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ cat busybox.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox2\n  namespace: default\nspec:\n  containers:\n  - name: busy\n    image: busybox\n    command:\n      - sleep\n      - "3600" \n\n$ kubectl create -f busybox.yaml\npod/busybox2 created\n\n$ kubectl get all\nNAME           READY   STATUS    RESTARTS   AGE\npod/busybox2   1/1     Running   0          22s\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   118d\n\n$ kubectl delete -f busybox.yaml\npod "busybox2" deleted\n')),(0,r.kt)("h4",{id:"lab-4-running-an-application-in-kubernetes"},"Lab 4. Running an Application in Kubernetes"),(0,r.kt)("p",null,"create an example pod again "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl create deployment cmd-nginx --image=nginx\ndeployment.apps/cmd-nginx created\n$ kubectl get deployment\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   0/1     1            0           8s\n$ kubectl get pod\nNAME                         READY   STATUS    RESTARTS   AGE\ncmd-nginx-57bb5f6747-bgqz4   1/1     Running   0          15s\n\n$ kubectl get deployment.apps\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   1/1     1            1           18h\n\n")),(0,r.kt)("p",null,"Create yaml referring existing apps."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ kubectl get deployment.apps -o yaml > myngnix.yaml\n\n$ cat myngnix.yaml\napiVersion: v1\nitems:\n- apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    annotations:\n      deployment.kubernetes.io/revision: "1"\n    creationTimestamp: "2022-06-24T05:14:35Z"\n    generation: 1\n    labels:\n      app: cmd-nginx\n    name: cmd-nginx\n    namespace: default\n    resourceVersion: "1619298"\n    uid: ab2c24aa-c432-42b0-ad9a-7340019c1c5c\n  spec:\n    progressDeadlineSeconds: 600\n    replicas: 1\n    revisionHistoryLimit: 10\n    selector:\n      matchLabels:\n        app: cmd-nginx\n    strategy:\n      rollingUpdate:\n        maxSurge: 25%\n        maxUnavailable: 25%\n      type: RollingUpdate\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          app: cmd-nginx\n      spec:\n        containers:\n        - image: nginx\n          imagePullPolicy: Always\n          name: nginx\n          resources: {}\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        schedulerName: default-scheduler\n        securityContext: {}\n        terminationGracePeriodSeconds: 30\n  status:\n    availableReplicas: 1\n    conditions:\n    - lastTransitionTime: "2022-06-24T05:14:48Z"\n      lastUpdateTime: "2022-06-24T05:14:48Z"\n      message: Deployment has minimum availability.\n      reason: MinimumReplicasAvailable\n      status: "True"\n      type: Available\n    - lastTransitionTime: "2022-06-24T05:14:35Z"\n      lastUpdateTime: "2022-06-24T05:14:48Z"\n      message: ReplicaSet "cmd-nginx-57bb5f6747" has successfully progressed.\n      reason: NewReplicaSetAvailable\n      status: "True"\n      type: Progressing\n    observedGeneration: 1\n    readyReplicas: 1\n    replicas: 1\n    updatedReplicas: 1\nkind: List\nmetadata:\n  resourceVersion: ""\n  selfLink: ""\n\n')),(0,r.kt)("p",null,"Remove unnecessary parts. ( creationTimestamp, resourceVersion, uid, status etc)     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ cp myngnix.yaml myngnix_org.yaml\n\n$ cat myngnix.yaml\napiVersion: v1\nitems:\n- apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    annotations:\n      deployment.kubernetes.io/revision: "1"\n    generation: 1\n    labels:\n      app: cmd-nginx\n    name: cmd-nginx\n    namespace: default\n  spec:\n    progressDeadlineSeconds: 600\n    replicas: 1\n    revisionHistoryLimit: 10\n    selector:\n      matchLabels:\n        app: cmd-nginx\n    strategy:\n      rollingUpdate:\n        maxSurge: 25%\n        maxUnavailable: 25%\n      type: RollingUpdate\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          app: cmd-nginx\n      spec:\n        containers:\n        - image: nginx\n          imagePullPolicy: Always\n          name: nginx\n          resources: {}\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        schedulerName: default-scheduler\n        securityContext: {}\n        terminationGracePeriodSeconds: 30\n\n$ diff myngnix_org.yaml myngnix.yaml\n8d7\n<     creationTimestamp: "2022-06-24T05:14:35Z"\n14,15d12\n<     resourceVersion: "1619298"\n<     uid: ab2c24aa-c432-42b0-ad9a-7340019c1c5c\n46,68d42\n<   status:\n<     availableReplicas: 1\n<     conditions:\n<     - lastTransitionTime: "2022-06-24T05:14:48Z"\n<       lastUpdateTime: "2022-06-24T05:14:48Z"\n<       message: Deployment has minimum availability.\n<       reason: MinimumReplicasAvailable\n<       status: "True"\n<       type: Available\n<     - lastTransitionTime: "2022-06-24T05:14:35Z"\n<       lastUpdateTime: "2022-06-24T05:14:48Z"\n<       message: ReplicaSet "cmd-nginx-57bb5f6747" has successfully progressed.\n<       reason: NewReplicaSetAvailable\n<       status: "True"\n<       type: Progressing\n<     observedGeneration: 1\n<     readyReplicas: 1\n<     replicas: 1\n<     updatedReplicas: 1\n< kind: List\n< metadata:\n<   resourceVersion: ""\n<   selfLink: ""\n\n')),(0,r.kt)("h3",{id:"05-managing-application"},"05 Managing application"),(0,r.kt)("h4",{id:"labels"},"Labels"),(0,r.kt)("p",null,"Many k8s API Objects are using labels to connect to other objects.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl get all --show-labels\nNAME                             READY   STATUS    RESTARTS   AGE   LABELS\npod/cmd-nginx-57bb5f6747-bgqz4   1/1     Running   0          20h   app=cmd-nginx,pod-template-hash=57bb5f6747\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   LABELS\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   34d   component=apiserver,provider=kubernetes\n\nNAME                        READY   UP-TO-DATE   AVAILABLE   AGE   LABELS\ndeployment.apps/cmd-nginx   1/1     1            1           20h   app=cmd-nginx\n\nNAME                                   DESIRED   CURRENT   READY   AGE   LABELS\nreplicaset.apps/cmd-nginx-57bb5f6747   1         1         1       20h   app=cmd-nginx,pod-template-hash=57bb5f6747\n[junsulee@fedora work]$ kubectl label pods ^C\n[junsulee@fedora work]$ kubectl get pods\nNAME                         READY   STATUS    RESTARTS   AGE\ncmd-nginx-57bb5f6747-bgqz4   1/1     Running   0          20h\n")),(0,r.kt)("p",null,"Set Label"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl label pods cmd-nginx-57bb5f6747-bgqz4 app-\npod/cmd-nginx-57bb5f6747-bgqz4 labeled\n$ kubectl get all --show-labels\nNAME                             READY   STATUS    RESTARTS   AGE   LABELS\npod/cmd-nginx-57bb5f6747-6clxd   1/1     Running   0          44s   app=cmd-nginx,pod-template-hash=57bb5f6747\npod/cmd-nginx-57bb5f6747-bgqz4   1/1     Running   0          20h   pod-template-hash=57bb5f6747\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   LABELS\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   34d   component=apiserver,provider=kubernetes\n\nNAME                        READY   UP-TO-DATE   AVAILABLE   AGE   LABELS\ndeployment.apps/cmd-nginx   1/1     1            1           20h   app=cmd-nginx\n\nNAME                                   DESIRED   CURRENT   READY   AGE   LABELS\nreplicaset.apps/cmd-nginx-57bb5f6747   1         1         1       20h   app=cmd-nginx,pod-template-hash=57bb5f6747\n")),(0,r.kt)("p",null,"Using ",(0,r.kt)("inlineCode",{parentName:"p"},"app0")," removes the label part ",(0,r.kt)("inlineCode",{parentName:"p"},"app=cmd-nginx")," from existing pod label, k8s created new pod with the existing name",(0,r.kt)("br",{parentName:"p"}),"\n","because k8s monitors the label and make sure specific amount of the label is available.",(0,r.kt)("br",{parentName:"p"}),"\n","It means k8s does not look at the pod itself but looking at the ",(0,r.kt)("inlineCode",{parentName:"p"},"label"),".      "),(0,r.kt)("p",null,"Display all objects with a specific label.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl get all --selector app=cmd-nginx\nNAME                             READY   STATUS    RESTARTS   AGE\npod/cmd-nginx-57bb5f6747-kmkjr   1/1     Running   0          14m\n\nNAME                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/cmd-nginx   1/1     1            1           52m\n\nNAME                                   DESIRED   CURRENT   READY   AGE\nreplicaset.apps/cmd-nginx-57bb5f6747   1         1         1       52m\n")),(0,r.kt)("h4",{id:"running-an-application"},"Running an application"),(0,r.kt)("p",null,"Do not use naked pods as it misses k8s benefits such as scalability etc.",(0,r.kt)("br",{parentName:"p"}),"\n","Better to use with a deployment that monitors and manages a pod.    "),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"Deployment")," specification from ",(0,r.kt)("inlineCode",{parentName:"p"},"template"),".    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"junsulee@fedora kubernetes]$ cat redis-deploy.yaml\n---\napiVersion: apps/v1beta1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  replicas:\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:alpine\n        ports:\n        - containerPort: 6379\n          name: redis\n")),(0,r.kt)("p",null,"Error due to wrong version.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'[junsulee@fedora kubernetes]$ kubectl create -f redis-deploy.yaml\nerror: unable to recognize "redis-deploy.yaml": no matches for kind "Deployment" in version "apps/v1beta\n')),(0,r.kt)("p",null,"Correcting and creating again.",(0,r.kt)("br",{parentName:"p"}),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"apiVersion: apps/v1beta1"),"  =>  ",(0,r.kt)("inlineCode",{parentName:"p"},"apiVersion: apps/v1"),"     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl create -f redis-deploy.yaml\ndeployment.apps/redis created\n[junsulee@fedora kubernetes]$ kubectl get deployment\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   1/1     1            1           20h\nredis       0/1     1            0           9s     <====\n[junsulee@fedora kubernetes]$ kubectl get pods\nNAME                         READY   STATUS              RESTARTS   AGE\ncmd-nginx-57bb5f6747-6clxd   1/1     Running             0          39m\ncmd-nginx-57bb5f6747-bgqz4   1/1     Running             0          20h\nredis-6fb5b985bc-6q7fk       0/1     ContainerCreating   0          16s  <=====  \n\n[junsulee@fedora kubernetes]$ kubectl get deployment --show-labels\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE    LABELS\ncmd-nginx   1/1     1            1           20h    app=cmd-nginx\nredis       1/1     1            1           2m8s   app=redis\n[junsulee@fedora kubernetes]$ kubectl get all --selector app=redis\nNAME                         READY   STATUS    RESTARTS   AGE\npod/redis-6fb5b985bc-6q7fk   1/1     Running   0          2m21s\n\nNAME                    READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/redis   1/1     1            1           2m21s\n\nNAME                               DESIRED   CURRENT   READY   AGE\nreplicaset.apps/redis-6fb5b985bc   1         1         1       2m21s\n\n")),(0,r.kt)("h4",{id:"namespace"},"namespace"),(0,r.kt)("p",null,"Download namespace related utilities.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"git clone https://github.com/ahmetb/kubectx  # Download kubectx packages.    \nsudo cp kubectx/kubensx /usr/local/bin\nsudo cp kubectx/kubens /usr/local/bin\n")),(0,r.kt)("p",null,"Namespace list    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubens\ndefault\nkube-node-lease\nkube-public\nkube-system\nkubernetes-dashboard\n\n[junsulee@fedora kubernetes]$ kubectl get ns\nNAME                   STATUS   AGE\ndefault                Active   34d\nkube-node-lease        Active   34d\nkube-public            Active   34d\nkube-system            Active   34d\nkubernetes-dashboard   Active   33d\n")),(0,r.kt)("p",null,"Switching between namespaces"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'[junsulee@fedora kubernetes]$ kubens kube-system\nContext "minikube" modified.\nActive namespace is "kube-system".\n[junsulee@fedora kubernetes]$ kubectl get all\nNAME                                   READY   STATUS    RESTARTS   AGE\npod/coredns-74ff55c5b-qgdjv            1/1     Running   1          34d\npod/etcd-minikube                      1/1     Running   26         34d\npod/kube-apiserver-minikube            1/1     Running   60         34d\npod/kube-controller-manager-minikube   1/1     Running   3          34d\npod/kube-proxy-x48k4                   1/1     Running   1          34d\npod/kube-scheduler-minikube            1/1     Running   1          34d\npod/storage-provisioner                1/1     Running   107        34d\n\nNAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\nservice/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   34d\n\nNAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ndaemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   34d\n\nNAME                      READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/coredns   1/1     1            1           34d\n\nNAME                                DESIRED   CURRENT   READY   AGE\nreplicaset.apps/coredns-74ff55c5b   1         1         1       34d\n[junsulee@fedora kubernetes]$ kubens\ndefault\nkube-node-lease\nkube-public\nkube-system\nkubernetes-dashboard\n[junsulee@fedora kubernetes]$ kubens default\nContext "minikube" modified.\nActive namespace is "default".\n[junsulee@fedora kubernetes]$ kubectl get all\nNAME                             READY   STATUS    RESTARTS   AGE\npod/cmd-nginx-57bb5f6747-6clxd   1/1     Running   0          89m\npod/cmd-nginx-57bb5f6747-bgqz4   1/1     Running   0          21h\npod/redis-6fb5b985bc-6q7fk       1/1     Running   0          50m\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   34d\n\nNAME                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/cmd-nginx   1/1     1            1           21h\ndeployment.apps/redis       1/1     1            1           50m\n\nNAME                                   DESIRED   CURRENT   READY   AGE\nreplicaset.apps/cmd-nginx-57bb5f6747   1         1         1       21h\nreplicaset.apps/redis-6fb5b985bc       1         1         1       50m\n')),(0,r.kt)("p",null,"K8s current configuration"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ cd\n[junsulee@fedora ~]$ cd .kube\n[junsulee@fedora .kube]$ cat config\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority: /home/junsulee/.minikube/ca.crt\n    extensions:\n    - extension:\n        last-update: Wed, 22 Jun 2022 12:12:20 AEST\n        provider: minikube.sigs.k8s.io\n        version: v1.20.0\n      name: cluster_info\n    server: https://192.168.39.25:8443\n  name: minikube\ncontexts:\n- context:\n    cluster: minikube\n    extensions:\n    - extension:\n        last-update: Wed, 22 Jun 2022 12:12:20 AEST\n        provider: minikube.sigs.k8s.io\n        version: v1.20.0\n      name: context_info\n    namespace: default\n    user: minikube\n  name: minikube\ncurrent-context: minikube\nkind: Config\npreferences: {}\nusers:\n- name: minikube\n  user:\n    client-certificate: /home/junsulee/.minikube/profiles/minikube/client.crt\n    client-key: /home/junsulee/.minikube/profiles/minikube/client.key\n\n")),(0,r.kt)("p",null,"Dashboard related resources    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kube]$ kubectl get all -n kubernetes-dashboard\nNAME                                            READY   STATUS    RESTARTS   AGE\npod/dashboard-metrics-scraper-f6647bd8c-7hgqz   1/1     Running   3          118d\npod/kubernetes-dashboard-968bcb79-lktd2         1/1     Running   69         118d\n\nNAME                                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE\nservice/dashboard-metrics-scraper   ClusterIP   10.105.137.234   <none>        8000/TCP   118d\nservice/kubernetes-dashboard        ClusterIP   10.101.187.187   <none>        80/TCP     118d\n\nNAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/dashboard-metrics-scraper   1/1     1            1           118d\ndeployment.apps/kubernetes-dashboard        1/1     1            1           118d\n\nNAME                                                  DESIRED   CURRENT   READY   AGE\nreplicaset.apps/dashboard-metrics-scraper-f6647bd8c   1         1         1       118d\nreplicaset.apps/kubernetes-dashboard-968bcb79         1         1         1       118d\n")),(0,r.kt)("p",null,"K8s core related resources"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kube]$ kubectl get all -n kube-system \nNAME                                   READY   STATUS    RESTARTS   AGE\npod/coredns-74ff55c5b-qgdjv            1/1     Running   3          119d\npod/etcd-minikube                      1/1     Running   33         119d\npod/kube-apiserver-minikube            1/1     Running   78         119d\npod/kube-controller-manager-minikube   1/1     Running   11         119d\npod/kube-proxy-x48k4                   1/1     Running   3          119d\npod/kube-scheduler-minikube            1/1     Running   3          119d\npod/storage-provisioner                1/1     Running   132        119d\n\nNAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\nservice/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   119d\n\nNAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ndaemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   119d\n\nNAME                      READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/coredns   1/1     1            1           119d\n\nNAME                                DESIRED   CURRENT   READY   AGE\nreplicaset.apps/coredns-74ff55c5b   1         1         1       119d\n")),(0,r.kt)("p",null,"Create a namespace and a pod on the namespace."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'\n[junsulee@fedora .kube]$ kubectl create ns myspace\nnamespace/myspace created\n\n[junsulee@fedora kubernetes]$ kubens\ndefault  <=== current\nkube-node-lease\nkube-public\nkube-system\nkubernetes-dashboard\nmyspace   <=== new\n\n[junsulee@fedora kubernetes]$ kubectl create -f busybox.yaml\npod/busybox2 created\n\n\n# expected error creating same name pod in the same namespace\n[junsulee@fedora kubernetes]$ kubectl create -f busybox.yaml\nError from server (AlreadyExists): error when creating "busybox.yaml": pods "busybox2" already exists\n\n[junsulee@fedora kubernetes]$ cp busybox.yaml busbox2.yaml\n\n# corrected namespace\n[junsulee@fedora kubernetes]$ cat busybox2.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox2\n  namespace: myspace\nspec:\n  containers:\n  - name: busy\n    image: busybox\n    command:\n      - sleep\n      - "3600"\n\n[junsulee@fedora kubernetes]$ kubectl create -f busybox2.yaml\npod/busybox2 created\n\n[junsulee@fedora kubernetes]$ kubectl get all -n myspace\nNAME           READY   STATUS    RESTARTS   AGE\npod/busybox2   1/1     Running   0          92s\n')),(0,r.kt)("h4",{id:"managing-scailability--num-of-replicas"},"managing scailability : num of replicas"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'junsulee@fedora kubernetes]$ kubectl get deployments.apps\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   1/1     1            1           22h\nredis       1/1     1            1           81m\n\n[junsulee@fedora kubernetes]$ kubectl edit deployment cmd-nginx   # change `replicas` from 1 to 2\ndeployment.apps/cmd-nginx edited\n\n\n[junsulee@fedora kubernetes]$ kubectl get deployments.apps\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   2/2     2            2           22h\nredis       1/1     1            1           86m\n\n[junsulee@fedora kubernetes]$ kubectl get deployments.apps\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   2/2     2            2           22h\nredis       1/1     1            1           86m \n\n[junsulee@fedora kubernetes]$ kubectl scale --replicas=1 cmd-nginx\nerror: the server doesn\'t have a resource type "cmd-nginx"\n[junsulee@fedora kubernetes]$ kubectl scale --replicas=1 deployment cmd-nginx\ndeployment.apps/cmd-nginx scaled\n\n[junsulee@fedora kubernetes]$ kubectl get deployments.apps\nNAME        READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx   1/1     1            1           22h\nredis       1/1     1            1           102m\n')),(0,r.kt)("h4",{id:"managing-application-updates-and-rollbacks"},"Managing application updates and rollbacks"),(0,r.kt)("p",null,"Create a pod for test"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl create deployment rollingnginx --image=nginx:1.8\ndeployment.apps/rollingnginx created\n[junsulee@fedora kubernetes]$ kubectl get all\nNAME                                READY   STATUS      RESTARTS   AGE\n...\npod/rollingnginx-785db9758d-7k6zc   1/1     Running     0          62s\n...\n\n[junsulee@fedora kubernetes]$ kubectl rollout history deployment\ndeployment.apps/cmd-nginx\nREVISION  CHANGE-CAUSE\n1         <none>\n\ndeployment.apps/redis\nREVISION  CHANGE-CAUSE\n1         <none>\n\ndeployment.apps/rollingnginx\nREVISION  CHANGE-CAUSE\n1         <none>\n")),(0,r.kt)("p",null,"Edit version."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl edit deployments.apps rollingnginx\n..\n- image: nginx:1.8    <=== changed to 1.15\n..\n\n[junsulee@fedora kubernetes]$ kubectl rollout history deployment\ndeployment.apps/cmd-nginx\nREVISION  CHANGE-CAUSE\n1         <none>\n\ndeployment.apps/redis\nREVISION  CHANGE-CAUSE\n1         <none>\n\ndeployment.apps/rollingnginx\nREVISION  CHANGE-CAUSE\n1         <none>\n2         <none>     <======\n\n\n[junsulee@fedora kubernetes]$ kubectl describe deployments.apps rollingnginx\nName:                   rollingnginx\nNamespace:              default\nCreationTimestamp:      Sat, 25 Jun 2022 14:03:49 +1000\nLabels:                 app=rollingnginx\nAnnotations:            deployment.kubernetes.io/revision: 2    <====\nSelector:               app=rollingnginx\nReplicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=rollingnginx\n  Containers:\n   nginx:\n    Image:        nginx:1.15\n    Port:         <none>\n    Host Port:    <none>\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   rollingnginx-58cff98f76 (1/1 replicas created)\nEvents:\n  Type    Reason             Age    From                   Message\n  ----    ------             ----   ----                   -------\n  Normal  ScalingReplicaSet  8m51s  deployment-controller  Scaled up replica set rollingnginx-785db9758d to 1\n  Normal  ScalingReplicaSet  104s   deployment-controller  Scaled up replica set rollingnginx-58cff98f76 to 1\n  Normal  ScalingReplicaSet  62s    deployment-controller  Scaled down replica set rollingnginx-785db9758d to 0\n")),(0,r.kt)("p",null,"Check version for each revision.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"\n[junsulee@fedora kubernetes]$ kubectl rollout history deployment rollingnginx --revision=1\ndeployment.apps/rollingnginx with revision #1\nPod Template:\n  Labels:   app=rollingnginx\n    pod-template-hash=785db9758d\n  Containers:\n   nginx:\n    Image:  nginx:1.8     <====\n    Port:   <none>\n    Host Port:  <none>\n    Environment:    <none>\n    Mounts: <none>\n  Volumes:  <none>\n\n$ kubectl rollout history deployment rollingnginx --revision=2\ndeployment.apps/rollingnginx with revision #2\nPod Template:\n  Labels:   app=rollingnginx\n    pod-template-hash=58cff98f76\n  Containers:\n   nginx:\n    Image:  nginx:1.15    <====\n    Port:   <none>\n    Host Port:  <none>\n    Environment:    <none>\n    Mounts: <none>\n  Volumes:  <none>\n")),(0,r.kt)("p",null,"Two replica sets are shown. Old one will be gone eventually.",(0,r.kt)("br",{parentName:"p"}),"\n","While old replica set is still being displayed, you can do rollback.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl get all\nNAME                                READY   STATUS    RESTARTS   AGE\npod/busybox2                        1/1     Running   1          72m\npod/cmd-nginx-57bb5f6747-6clxd      1/1     Running   0          173m\npod/cmd-nginx-57bb5f6747-bgqz4      1/1     Running   0          23h\npod/redis-6fb5b985bc-6q7fk          1/1     Running   0          134m\npod/rollingnginx-58cff98f76-997zw   1/1     Running   0          6m15s\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   34d\n\nNAME                           READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/cmd-nginx      1/1     1            1           23h\ndeployment.apps/redis          1/1     1            1           134m\ndeployment.apps/rollingnginx   1/1     1            1           13m\n\nNAME                                      DESIRED   CURRENT   READY   AGE\nreplicaset.apps/cmd-nginx-57bb5f6747      1         1         1       23h\nreplicaset.apps/redis-6fb5b985bc          1         1         1       134m\nreplicaset.apps/rollingnginx-58cff98f76   1         1         1       6m17s    <=== new revision   \nreplicaset.apps/rollingnginx-785db9758d   0         0         0       13m      <=== old one is emptied.    \n")),(0,r.kt)("p",null,"Rollback "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl rollout undo deployment rollingnginx --to-revision=1\ndeployment.apps/rollingnginx rolled back\n\n$ kubectl get all\nNAME                                READY   STATUS    RESTARTS   AGE\npod/busybox2                        1/1     Running   1          76m\npod/cmd-nginx-57bb5f6747-6clxd      1/1     Running   0          177m\npod/cmd-nginx-57bb5f6747-bgqz4      1/1     Running   0          23h\npod/redis-6fb5b985bc-6q7fk          1/1     Running   0          138m\npod/rollingnginx-785db9758d-kzgd5   1/1     Running   0          79s\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   34d\n\nNAME                           READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/cmd-nginx      1/1     1            1           23h\ndeployment.apps/redis          1/1     1            1           138m\ndeployment.apps/rollingnginx   1/1     1            1           16m\n\nNAME                                      DESIRED   CURRENT   READY   AGE\nreplicaset.apps/cmd-nginx-57bb5f6747      1         1         1       23h\nreplicaset.apps/redis-6fb5b985bc          1         1         1       138m\nreplicaset.apps/rollingnginx-58cff98f76   0         0         0       9m45s\nreplicaset.apps/rollingnginx-785db9758d   1         1         1       16m   <==== pod went to old one   \n\n")),(0,r.kt)("h4",{id:"lab-05-managing-deployment"},"Lab 05 Managing deployment"),(0,r.kt)("p",null,"Create yaml file only. ( --dry-run  )       "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl create deployment lab5-nginx --image=nginx --dry-run --output=yaml > lab5-nginx.yaml\n")),(0,r.kt)("p",null,"Change.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"$ cat lab5-nginx.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: lab5-ngnix\n  name: lab5-ngnix\nspec:\n  replicas: 3     ## 1 -> 3\n  selector:\n    matchLabels:\n      app: lab5-ngnix\n  strategy: {}\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: lab5-ngnix\n    spec:\n      containers:\n      - image: ngnix:1.8  ## ngnix : latest version. specify preferred version.    \n        name: ngnix\n        resources: {}\nstatus: {}\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl create -f lab5-nginx.yaml  # create\n$ kubectl get all --selector app=lab5-nginx  # list all resources with the tabel   \n\nNAME                              READY   STATUS    RESTARTS   AGE\npod/lab5-nginx-75588bfdc4-4vkzv   1/1     Running   0          56s\npod/lab5-nginx-75588bfdc4-78ms9   1/1     Running   0          56s\npod/lab5-nginx-75588bfdc4-98krb   1/1     Running   0          56s\n\nNAME                         READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/lab5-nginx   3/3     3            3           56s\n\nNAME                                    DESIRED   CURRENT   READY   AGE\nreplicaset.apps/lab5-nginx-75588bfdc4   3         3         3       56s\n\n\n$ kubectl scale deployment lab5-nginx --replicas=4   # increase   \n\n$ kubectl get all --selector app=lab5-nginx\nNAME                              READY   STATUS    RESTARTS   AGE\npod/lab5-nginx-75588bfdc4-4vkzv   1/1     Running   0          2m15s\npod/lab5-nginx-75588bfdc4-78ms9   1/1     Running   0          2m15s\npod/lab5-nginx-75588bfdc4-98krb   1/1     Running   0          2m15s\npod/lab5-nginx-75588bfdc4-r8m2f   1/1     Running   0          12s\n\nNAME                         READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/lab5-nginx   4/4     4            4           2m15s\n\nNAME                                    DESIRED   CURRENT   READY   AGE\nreplicaset.apps/lab5-nginx-75588bfdc4   4         4         4       2m15s\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl edit deployments.apps lab5-nginx   # change the version  \n...\n      containers:\n      - image: nginx\n...\n\n[root@api.jscp4d.cp.fyre.ibm.com work]# kubectl get all --selector app=lab5-nginx\nNAME                              READY   STATUS    RESTARTS   AGE\npod/lab5-nginx-75f4f8d9f7-295vn   1/1     Running   0          27s\npod/lab5-nginx-75f4f8d9f7-7rs9c   1/1     Running   0          17s\npod/lab5-nginx-75f4f8d9f7-ldcs6   1/1     Running   0          27s\npod/lab5-nginx-75f4f8d9f7-xl98h   1/1     Running   0          17s\n\nNAME                         READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/lab5-nginx   4/4     4            4           4m48s\n\nNAME                                    DESIRED   CURRENT   READY   AGE\nreplicaset.apps/lab5-nginx-75588bfdc4   0         0         0       4m48s\nreplicaset.apps/lab5-nginx-75f4f8d9f7   4         4         4       27s     <===== new version  deployment     \n\n")),(0,r.kt)("h3",{id:"06-exposing-applications-networking"},"06 Exposing applications (Networking)"),(0,r.kt)("p",null,"Create a yaml with multiple pods.",(0,r.kt)("br",{parentName:"p"}),"\n","Not caring about what the pods do but focusing on how network is organized.      "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'$ cat busybox_multi.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: verybusy\n  namespace: default\nspec:\n  containers:\n  - name: busy\n    image: busybox\n    command:\n      - sleep\n      - "3600" \n  - name: box\n    image: busybox\n    command:\n      - sleep\n      - "3600" \n\n\n$ kubectl create -f busybox_multi.yaml\npod/verybusy created\n')),(0,r.kt)("p",null,"Each pod has its own IP addresses.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl get pods -o wide\nNAME                            READY   STATUS    RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES\ncmd-nginx-57bb5f6747-hznc7      1/1     Running   1          5d23h   172.17.0.5    minikube   <none>           <none>\ncmd-nginx-57bb5f6747-kmkjr      1/1     Running   1          5d23h   172.17.0.3    minikube   <none>           <none>\nlab5-nginx-7777d7964c-5pc68     1/1     Running   0          33m     172.17.0.13   minikube   <none>           <none>\nlab5-nginx-7777d7964c-rkfz2     1/1     Running   0          33m     172.17.0.14   minikube   <none>           <none>\nlab5-nginx-7777d7964c-v9kn6     1/1     Running   0          33m     172.17.0.15   minikube   <none>           <none>\nlab5-nginx-7777d7964c-vdlxm     1/1     Running   0          33m     172.17.0.11   minikube   <none>           <none>\nredis-6fb5b985bc-s6gpq          1/1     Running   0          5d8h    172.17.0.8    minikube   <none>           <none>\nrollingnginx-785db9758d-p5k8v   1/1     Running   0          25h     172.17.0.9    minikube   <none>           <none>\nverybusy                        2/2     Running   0          42s     172.17.0.10   minikube   <none>           <none>      <======\n")),(0,r.kt)("p",null,"IP address is POD property, not container's.       "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ kubectl describe pod verybusy\nName:         verybusy\nNamespace:    default\nPriority:     0\nNode:         minikube/192.168.39.25\nStart Time:   Fri, 23 Sep 2022 14:50:30 +1000\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           172.17.0.10\nIPs:\n  IP:  172.17.0.10     # <==========\nContainers:\n  busy:\n    Container ID:  docker://995e596ca7c7953c21955db1506f724d57db17251440c397878efed8714a61a2\n    Image:         busybox\n    Image ID:      docker-pullable://busybox@sha256:ad9bd57a3a57cc95515c537b89aaa69d83a6df54c4050fcf2b41ad367bec0cd5\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sleep\n      3600\n    State:          Running\n      Started:      Fri, 23 Sep 2022 14:50:44 +1000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vrnvj (ro)\n  box:\n    Container ID:  docker://e1beec661f02024c461cb72bf8013661a781c8ae1d6d65c5e01936c3ab9e6d08\n    Image:         busybox\n    Image ID:      docker-pullable://busybox@sha256:ad9bd57a3a57cc95515c537b89aaa69d83a6df54c4050fcf2b41ad367bec0cd5\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sleep\n      3600\n    State:          Running\n      Started:      Fri, 23 Sep 2022 14:50:50 +1000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vrnvj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-vrnvj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-vrnvj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age    From               Message\n  ----    ------     ----   ----               -------\n  Normal  Scheduled  5m47s  default-scheduler  Successfully assigned default/verybusy to minikube\n  Normal  Pulling    5m41s  kubelet            Pulling image "busybox"\n  Normal  Pulled     5m37s  kubelet            Successfully pulled image "busybox" in 4.068525177s\n  Normal  Created    5m35s  kubelet            Created container busy\n  Normal  Started    5m33s  kubelet            Started container busy\n  Normal  Pulling    5m33s  kubelet            Pulling image "busybox"\n  Normal  Pulled     5m29s  kubelet            Successfully pulled image "busybox" in 3.699821125s\n  Normal  Created    5m27s  kubelet            Created container box\n  Normal  Started    5m26s  kubelet            Started container box\n')),(0,r.kt)("p",null,"Log into containers and check ip address.",(0,r.kt)("br",{parentName:"p"}),"\n","Both container shows the same IP address.",(0,r.kt)("br",{parentName:"p"}),"\n","Note that conatiner is not a virtual machine but an application.       "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl exec -it verybusy -c busy /bin/sh\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.\n/ # \n/ # ip a\n..\n2: sit0@NONE: <NOARP> mtu 1480 qdisc noop qlen 1000\n    link/sit 0.0.0.0 brd 0.0.0.0\n60: eth0@if61: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue \n    link/ether 02:42:ac:11:00:0a brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.10/16 brd 172.17.255.255 scope global eth0     <======\n       valid_lft forever preferred_lft forever\n/ # exit\n\n\n$ kubectl exec -it verybusy -c box /bin/sh\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.\n/ # ip ad\n...\n2: sit0@NONE: <NOARP> mtu 1480 qdisc noop qlen 1000\n    link/sit 0.0.0.0 brd 0.0.0.0\n60: eth0@if61: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue \n    link/ether 02:42:ac:11:00:0a brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.10/16 brd 172.17.255.255 scope global eth0     <======\n       valid_lft forever preferred_lft forever\n\n\n")),(0,r.kt)("p",null,"What if one conatiner wants to connect to other container ?",(0,r.kt)("br",{parentName:"p"}),"\n","It's same as multiple application in a server using internal IP stack, IPC or port forwarding. K8s pos is not different.",(0,r.kt)("br",{parentName:"p"}),"\n","Pod is ultimate entity having an ip address.      "),(0,r.kt)("h4",{id:"expose-a-deployment"},"Expose a deployment"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl get svc\nNAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nkubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   125d\n[junsulee@fedora kubernetes]$ kubectl get deployment\nNAME           READY   UP-TO-DATE   AVAILABLE   AGE\ncmd-nginx      1/1     1            1           6d\nlab5-nginx     4/4     4            4           105m\nredis          1/1     1            1           5d9h\nrollingnginx   1/1     1            1           26h\n[junsulee@fedora kubernetes]$ kubectl expose deployment rollingnginx --port=80 --target-port=80\nservice/rollingnginx exposed\n[junsulee@fedora kubernetes]$ kubectl get svc\nNAME           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\nkubernetes     ClusterIP   10.96.0.1        <none>        443/TCP   125d\nrollingnginx   ClusterIP   10.100.255.163   <none>        80/TCP    4s      <=====\n\n[junsulee@fedora kubernetes]$ kubectl describe svc rollingnginx\nName:              rollingnginx\nNamespace:         default\nLabels:            app=rollingnginx  <==== service uses Label   \nAnnotations:       <none>\nSelector:          app=rollingnginx\nType:              ClusterIP\nIP Families:       <none>\nIP:                10.100.255.163    <=====\nIPs:               10.100.255.163\nPort:              <unset>  80/TCP   <======\nTargetPort:        80/TCP\nEndpoints:         172.17.0.9:80     <=====\nSession Affinity:  None\nEvents:            <none>\n\n[junsulee@fedora kubernetes]$ kubectl get pod -o wide\nNAME                            READY   STATUS    RESTARTS   AGE    IP            NODE       NOMINATED NODE   READINESS GATES\n...\nrollingnginx-785db9758d-p5k8v   1/1     Running   0          26h    172.17.0.9    minikube   <none>           <none>  <====\n...\n")),(0,r.kt)("h4",{id:"scaling-the-deployment-will-add-ip-endpoints-as-pods-increases"},"Scaling the deployment will add IP Endpoints as PODs increases."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'[junsulee@fedora kubernetes]$ kubectl describe svc rollingnginx\nName:              rollingnginx\nNamespace:         default\nLabels:            app=rollingnginx\nAnnotations:       <none>\nSelector:          app=rollingnginx\nType:              ClusterIP\nIP Families:       <none>\nIP:                10.100.255.163\nIPs:               10.100.255.163\nPort:              <unset>  80/TCP\nTargetPort:        80/TCP\nEndpoints:         172.17.0.12:80,172.17.0.16:80,172.17.0.17:80 + 1 more...     <====\nSession Affinity:  None\nEvents:\n  Type     Reason                        Age   From                       Message\n  ----     ------                        ----  ----                       -------\n  Warning  FailedToUpdateEndpointSlices  11s   endpoint-slice-controller  Error updating Endpoint Slices for Service default/rollingnginx: failed to update rollingnginx-5fgpm EndpointSlice for Service default/rollingnginx: Operation cannot be fulfilled on endpointslices.discovery.k8s.io "rollingnginx-5fgpm": the object has been modified; please apply your changes to the latest version and try again\n\n\n[junsulee@fedora kubernetes]$ kubectl get pod -o wide\nNAME                            READY   STATUS    RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES\n...\nrollingnginx-785db9758d-npzw7   1/1     Running   0          3m14s   172.17.0.12   minikube   <none>           <none>\nrollingnginx-785db9758d-p5k8v   1/1     Running   0          26h     172.17.0.9    minikube   <none>           <none>\nrollingnginx-785db9758d-szglg   1/1     Running   0          3m13s   172.17.0.17   minikube   <none>           <none>\nrollingnginx-785db9758d-vpwc7   1/1     Running   0          3m13s   172.17.0.16   minikube   <none>           <none>\n...\n')),(0,r.kt)("p",null,"Working with yaml file,  it contains everything for service.",(0,r.kt)("br",{parentName:"p"}),"\n","Not much information.",(0,r.kt)("br",{parentName:"p"}),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"Label")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"selector")," is important.",(0,r.kt)("br",{parentName:"p"}),"\n","Services is not connect to an one deployment.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl expose deployment rollingnginx --port=80 --target-port=80 --dry-run -o yaml > svc.yaml\n\n$ cat svc.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  creationTimestamp: null\n  labels:   \n    app: rollingnginx\n  name: rollingnginx\nspec:\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 80\n  selector: \n    app: rollingnginx\nstatus:\n  loadBalancer: {}\n")),(0,r.kt)("h4",{id:"using-dns-in-k8s"},"Using DNS in k8s."),(0,r.kt)("p",null,"K8s DNS service "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora work]$ kubectl get pods -n kube-system -o wide\nNAME                               READY   STATUS    RESTARTS   AGE    IP              NODE       NOMINATED NODE   READINESS GATES\ncoredns-74ff55c5b-qgdjv            1/1     Running   3          125d   172.17.0.4      minikube   <none>           <none>        <==========\netcd-minikube                      1/1     Running   35         125d   192.168.39.25   minikube   <none>           <none>\nkube-apiserver-minikube            1/1     Running   83         125d   192.168.39.25   minikube   <none>           <none>\nkube-controller-manager-minikube   1/1     Running   11         125d   192.168.39.25   minikube   <none>           <none>\nkube-proxy-x48k4                   1/1     Running   3          125d   192.168.39.25   minikube   <none>           <none>\nkube-scheduler-minikube            1/1     Running   3          125d   192.168.39.25   minikube   <none>           <none>\nstorage-provisioner                1/1     Running   139        125d   192.168.39.25   minikube   <none>           <none>\n\n\n[junsulee@fedora work]$ kubectl describe pod coredns-74ff55c5b-qgdjv -n kube-system\nName:                 coredns-74ff55c5b-qgdjv\nNamespace:            kube-system\nPriority:             2000000000\nPriority Class Name:  system-cluster-critical\nNode:                 minikube/192.168.39.25\nStart Time:           Sat, 21 May 2022 15:12:15 +1000\nLabels:               k8s-app=kube-dns\n                      pod-template-hash=74ff55c5b\nAnnotations:          <none>\nStatus:               Running\nIP:                   172.17.0.4\nIPs:\n  IP:           172.17.0.4\nControlled By:  ReplicaSet/coredns-74ff55c5b\nContainers:\n  coredns:\n    Container ID:  docker://2f577513304ad5e32f49f69d054f26b5a9d9c0b595dce7741bca319b7817f486\n    Image:         k8s.gcr.io/coredns:1.7.0\n    Image ID:      docker-pullable://k8s.gcr.io/coredns@sha256:73ca82b4ce829766d4f1f10947c3a338888f876fbed0540dc849c89ff256e90c\n    Ports:         53/UDP, 53/TCP, 9153/TCP\n    Host Ports:    0/UDP, 0/TCP, 0/TCP\n    Args:\n      -conf\n      /etc/coredns/Corefile\n    State:          Running\n      Started:      Sun, 18 Sep 2022 06:33:23 +1000\n    Last State:     Terminated\n      Reason:       Error\n      Exit Code:    255\n      Started:      Sat, 17 Sep 2022 12:10:25 +1000\n      Finished:     Sun, 18 Sep 2022 06:28:42 +1000\n    Ready:          True\n    Restart Count:  3\n    Limits:\n      memory:  170Mi\n    Requests:\n      cpu:        100m\n      memory:     70Mi\n    Liveness:     http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5\n    Readiness:    http-get http://:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3\n    Environment:  <none>\n    Mounts:\n      /etc/coredns from config-volume (ro)\n      /var/run/secrets/kubernetes.io/serviceaccount from coredns-token-dwpds (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  config-volume:\n    Type:      ConfigMap (a volume populated by a ConfigMap)\n    Name:      coredns\n    Optional:  false\n  coredns-token-dwpds:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  coredns-token-dwpds\n    Optional:    false\nQoS Class:       Burstable\nNode-Selectors:  kubernetes.io/os=linux\nTolerations:     CriticalAddonsOnly op=Exists\n                 node-role.kubernetes.io/control-plane:NoSchedule\n                 node-role.kubernetes.io/master:NoSchedule\n                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:          <none>\n\n\n")),(0,r.kt)("h4",{id:"nslookup"},"nslookup"),(0,r.kt)("p",null,"Create a pod from where we can run ",(0,r.kt)("inlineCode",{parentName:"p"},"nslookup")," command.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ cat busybox.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\n  namespace: default\nspec:\n  containers:\n  - name: busy\n    image: busybox\n    command:\n      - sleep\n      - "3600" \n\n$ kubectl create -f busybox.yaml\npod/busybox created\n\n')),(0,r.kt)("p",null,"Check existing services"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl get svc -o wide\nNAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE    SELECTOR\nkubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   125d   <none>\n")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"nslookup"),"      "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl exec -it busybox -- nslookup kubernetes\nServer:     10.96.0.10    <=== name server\nAddress:    10.96.0.10:53\n\nName:   kubernetes.default.svc.cluster.local\nAddress: 10.96.0.1      <=====\n\n*** Can't find kubernetes.svc.cluster.local: No answer\n*** Can't find kubernetes.cluster.local: No answer\n*** Can't find kubernetes.default.svc.cluster.local: No answer\n*** Can't find kubernetes.svc.cluster.local: No answer\n*** Can't find kubernetes.cluster.local: No answer\n\n")),(0,r.kt)("p",null,"K8s automatically adds DNS configuration to pods.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl exec -it busybox -- cat /etc/resolv.conf\nnameserver 10.96.0.10\nsearch default.svc.cluster.local svc.cluster.local cluster.local\noptions ndots:5\n")),(0,r.kt)("p",null,"Example from an OCP.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"root@bastion ~]# kubectl exec -it c-db2oltp-1655862364134421-db2u-0 cat /etc/resolv.conf\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.\nsearch sandy.svc.cluster.local svc.cluster.local cluster.local js.ocp.adl\nnameserver 136.32.0.10\noptions ndots:2\n")),(0,r.kt)("h4",{id:"ingress"},"Ingress"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"HTTP/HTTPS"),(0,r.kt)("li",{parentName:"ul"},"Services get externally reachable URLs"),(0,r.kt)("li",{parentName:"ul"},"can load balance"),(0,r.kt)("li",{parentName:"ul"},"can take care of TLS/SSL termination.   "),(0,r.kt)("li",{parentName:"ul"},"Needs an Ingress Controller to do the work.     ")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Other services types are exposed using the ",(0,r.kt)("inlineCode",{parentName:"p"},"NodePort")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"LoadBalancer")," Service type.     ")),(0,r.kt)("p",null,"Enable ingress.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ minikube addons list\n|-----------------------------|----------|--------------|\n|         ADDON NAME          | PROFILE  |    STATUS    |\n|-----------------------------|----------|--------------|\n| ambassador                  | minikube | disabled     |\n| auto-pause                  | minikube | disabled     |\n| csi-hostpath-driver         | minikube | disabled     |\n| dashboard                   | minikube | enabled \u2705   |\n| default-storageclass        | minikube | enabled \u2705   |\n| efk                         | minikube | disabled     |\n| freshpod                    | minikube | disabled     |\n| gcp-auth                    | minikube | disabled     |\n| gvisor                      | minikube | disabled     |\n| helm-tiller                 | minikube | disabled     |\n| ingress                     | minikube | disabled     |\n| ingress-dns                 | minikube | disabled     |\n| istio                       | minikube | disabled     |\n| istio-provisioner           | minikube | disabled     |\n| kubevirt                    | minikube | disabled     |\n| logviewer                   | minikube | disabled     |\n| metallb                     | minikube | disabled     |\n| metrics-server              | minikube | disabled     |\n| nvidia-driver-installer     | minikube | disabled     |\n| nvidia-gpu-device-plugin    | minikube | disabled     |\n| olm                         | minikube | disabled     |\n| pod-security-policy         | minikube | disabled     |\n| registry                    | minikube | disabled     |\n| registry-aliases            | minikube | disabled     |\n| registry-creds              | minikube | disabled     |\n| storage-provisioner         | minikube | enabled \u2705   |\n| storage-provisioner-gluster | minikube | disabled     |\n| volumesnapshots             | minikube | disabled     |\n|-----------------------------|----------|--------------|\n\n[junsulee@fedora kubernetes]$ minikube addons enable ingress\n  - Using image k8s.gcr.io/ingress-nginx/controller:v0.44.0\n  - Using image docker.io/jettech/kube-webhook-certgen:v1.5.1\n  - Using image docker.io/jettech/kube-webhook-certgen:v1.5.1\n* Verifying ingress addon...\n* The 'ingress' addon is enabled\n\n[junsulee@fedora kubernetes]$ minikube addons enable ingress-dns\n  - Using image cryptexlabs/minikube-ingress-dns:0.3.0\n* The 'ingress-dns' addon is enabled\n[junsulee@fedora kubernetes]$ minikube addons list\n|-----------------------------|----------|--------------|\n|         ADDON NAME          | PROFILE  |    STATUS    |\n|-----------------------------|----------|--------------|\n| ambassador                  | minikube | disabled     |\n| auto-pause                  | minikube | disabled     |\n| csi-hostpath-driver         | minikube | disabled     |\n| dashboard                   | minikube | enabled \u2705   |\n| default-storageclass        | minikube | enabled \u2705   |\n| efk                         | minikube | disabled     |\n| freshpod                    | minikube | disabled     |\n| gcp-auth                    | minikube | disabled     |\n| gvisor                      | minikube | disabled     |\n| helm-tiller                 | minikube | disabled     |\n| ingress                     | minikube | enabled \u2705   |\n| ingress-dns                 | minikube | enabled \u2705   |\n| istio                       | minikube | disabled     |\n| istio-provisioner           | minikube | disabled     |\n| kubevirt                    | minikube | disabled     |\n| logviewer                   | minikube | disabled     |\n| metallb                     | minikube | disabled     |\n| metrics-server              | minikube | disabled     |\n| nvidia-driver-installer     | minikube | disabled     |\n| nvidia-gpu-device-plugin    | minikube | disabled     |\n| olm                         | minikube | disabled     |\n| pod-security-policy         | minikube | disabled     |\n| registry                    | minikube | disabled     |\n| registry-aliases            | minikube | disabled     |\n| registry-creds              | minikube | disabled     |\n| storage-provisioner         | minikube | enabled \u2705   |\n| storage-provisioner-gluster | minikube | disabled     |\n| volumesnapshots             | minikube | disabled     |\n|-----------------------------|----------|--------------|\n\n")),(0,r.kt)("p",null,"Create ingress controller.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ cat nginx-in2.yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: nginx-ingress\n  annotations:     ## comment filed \n    ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n  - host:\n    http:\n      paths:\n      - path: /nginxserver\n        backend:\n          serviceName: nginx-dash\n          servicePort: 80\n\n[junsulee@fedora kubernetes]$ kubectl create -f nginx-in2.yaml\nWarning: extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress\ningress.extensions/nginx-ingress created\n")),(0,r.kt)("p",null,"Normal Ingress example.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ cat ingress-virtual-hosting.yaml\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: name-virtual-host-ingress\nspec:\n  rules:\n  - host: first.bar.com     ## <=== DNS should know about this     \n    http:\n      paths:\n      - backend:\n          serviceName: service1\n          servicePort: 80\n  - host: second.foo.com\n    http:\n      paths:\n      - backend:\n          serviceName: service2\n          servicePort: 80\n  - http:\n      paths:\n      - backend: \n          serviceName: service3\n          servicePort: 80\n")),(0,r.kt)("h4",{id:"lab-6-exposing-pods"},"Lab 6 Exposing Pods"),(0,r.kt)("p",null,"Create a pod.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ cat lab6_nginx_pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: lab6-nginx-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n[junsulee@fedora kubernetes]$ kubectl create -f lab6_nginx_pod.yaml\npod/lab6-nginx-pod created\n\n$ kubectl get pods -o wide\nNAME                            READY   STATUS    RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES\nbusybox                         1/1     Running   6          6h5m    172.17.0.9    minikube   <none>           <none>\ncmd-nginx-57bb5f6747-hznc7      1/1     Running   1          7d1h    172.17.0.5    minikube   <none>           <none>\ncmd-nginx-57bb5f6747-kmkjr      1/1     Running   1          7d      172.17.0.3    minikube   <none>           <none>\nlab5-nginx-7777d7964c-rkfz2     1/1     Running   0          26h     172.17.0.14   minikube   <none>           <none>\nlab5-nginx-7777d7964c-v9kn6     1/1     Running   0          26h     172.17.0.15   minikube   <none>           <none>\nlab6-nginx-pod                  1/1     Running   0          3m27s   172.17.0.13   minikube   <none>           <none>     <========\nredis-6fb5b985bc-s6gpq          1/1     Running   0          6d9h    172.17.0.8    minikube   <none>           <none>\nrollingnginx-7dbfcbddb7-rb5wk   1/1     Running   0          23h     172.17.0.12   minikube   <none>           <none>\nverybusy                        2/2     Running   50         25h     172.17.0.10   minikube   <none>           <none>\n[junsulee@fedora kubernetes]$ \n\n")),(0,r.kt)("p",null,"expose failure due to no label on the pod. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl expose pod lab6-nginx-pod --type=NodePort\nerror: couldn't retrieve selectors via --selector flag or introspection: the pod has no labels and cannot be exposed\nSee 'kubectl expose -h' for help and examples\n")),(0,r.kt)("p",null,"Create again adding labels   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ cat lab6_nginx_pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: lab6-nginx-pod\n  labels:     ## added\n    name: lab6-nginx-pod   ## added\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n\n$ kubectl create -f lab6_nginx_pod.yaml\npod/lab6-nginx-pod created\n\n[junsulee@fedora kubernetes]$ kubectl get pods -o wide\nNAME                            READY   STATUS    RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES\n...\nlab6-nginx-pod                  1/1     Running   0          29s     172.17.0.13   minikube   <none>           <none>\n...\n\n$ kubectl get pods --show-labels\nNAME                            READY   STATUS    RESTARTS   AGE     LABELS\n...\nlab6-nginx-pod                  1/1     Running   0          2m9s    name=lab6-nginx-pod    <======================\n...\n")),(0,r.kt)("p",null,"Expose again    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl expose pod lab6-nginx-pod --type=NodePort --port=8080\nservice/lab6-nginx-pod exposed\n\n[junsulee@fedora kubernetes]$ kubectl describe service lab6-nginx-pod\nName:                     lab6-nginx-pod\nNamespace:                default\nLabels:                   name=lab6-nginx-pod\nAnnotations:              <none>\nSelector:                 name=lab6-nginx-pod\nType:                     NodePort\nIP Families:              <none>\nIP:                       10.100.194.64   => (?) what's this IP ? CLUSTER-IP \nIPs:                      10.100.194.64\nPort:                     <unset>  8080/TCP\nTargetPort:               8080/TCP\nNodePort:                 <unset>  30390/TCP\nEndpoints:                172.17.0.13:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   <none>\n\n\n$ kubectl get svc\nNAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n...\nlab6-nginx-pod   NodePort    10.100.194.64   <none>        8080:30390/TCP   6m7s\n")),(0,r.kt)("h3",{id:"07-managing-pod-volumes"},"07 Managing Pod Volumes"),(0,r.kt)("h4",{id:"managing-pod-volumes"},"Managing Pod Volumes"),(0,r.kt)("p",null,"Create a pod using ",(0,r.kt)("inlineCode",{parentName:"p"},"emptyDir")," type volumne.",(0,r.kt)("br",{parentName:"p"}),"\n","That is temporary during pods's life time. See ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl explain pod.spec.volumes"),".      "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'$ cat volumes.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: vol2\nspec:\n  containers:\n  - name: centos2\n    image: centos:7\n    command:\n      - sleep\n      - "3600"\n    volumeMounts:\n    - mountPath: /test\n      name: test\n  restartPolicy: Always\n  volumes:\n    - name: test\n      emptyDir: {}\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl create -f volumes.yaml\npod/vol2 created\n\n[junsulee@fedora kubernetes]$ kubectl get pod\nNAME   READY   STATUS              RESTARTS   AGE\nvol2   0/1     ContainerCreating   0          58s\n[junsulee@fedora kubernetes]$ kubectl get pod\nNAME   READY   STATUS              RESTARTS   AGE\nvol2   0/1     ContainerCreating   0          67s\n[junsulee@fedora kubernetes]$ kubectl get pod\nNAME   READY   STATUS    RESTARTS   AGE\nvol2   1/1     Running   0          2m16s\n")),(0,r.kt)("p",null,"It created volume ",(0,r.kt)("inlineCode",{parentName:"p"},"test")," with ",(0,r.kt)("inlineCode",{parentName:"p"},"emptyDir")," type and mount it as ",(0,r.kt)("inlineCode",{parentName:"p"},"/test")," new pod with ",(0,r.kt)("inlineCode",{parentName:"p"},"emptyDir")," type.       "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'[junsulee@fedora kubernetes]$ kubectl describe pod vol2\nName:         vol2\nNamespace:    default\nPriority:     0\nNode:         minikube/192.168.39.25\nStart Time:   Sat, 08 Oct 2022 16:50:50 +1100\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           172.17.0.6\nIPs:\n  IP:  172.17.0.6\nContainers:\n  centos2:\n    Container ID:  docker://1e6aba5fa4cf0a6f1f1f05a613b7ca98d548e37d106c01b13ac613c45d20da24\n    Image:         centos:7\n    Image ID:      docker-pullable://centos@sha256:c73f515d06b0fa07bb18d8202035e739a494ce760aa73129f60f4bf2bd22b407\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sleep\n      3600\n    State:          Running\n      Started:      Sat, 08 Oct 2022 16:52:04 +1100\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /test from test (rw)     <=====\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hfn84 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  test:\n    Type:       EmptyDir (a temporary directory that shares a pod\'s lifetime)         <=======\n    Medium:     \n    SizeLimit:  <unset>\n  default-token-hfn84:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hfn84\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age    From               Message\n  ----    ------     ----   ----               -------\n  Normal  Scheduled  2m51s  default-scheduler  Successfully assigned default/vol2 to minikube\n  Normal  Pulling    2m43s  kubelet            Pulling image "centos:7"\n  Normal  Pulled     103s   kubelet            Successfully pulled image "centos:7" in 1m0.434691784s\n  Normal  Created    99s    kubelet            Created container centos2\n  Normal  Started    97s    kubelet            Started container centos2\n')),(0,r.kt)("p",null,"Create a test file into the pod.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl exec -it vol2 touch /test/testfile\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.\n$ kubectl exec -it vol2 -- ls -l /test/testfile\n-rw-r--r-- 1 root root 0 Oct  8 05:56 /test/testfile\n\n$ kubectl exec -it vol2 -- df -h\nFilesystem      Size  Used Avail Use% Mounted on\noverlay          17G  3.1G   13G  20% /\ntmpfs            64M     0   64M   0% /dev\ntmpfs           2.0G     0  2.0G   0% /sys/fs/cgroup\n/dev/vda1        17G  3.1G   13G  20% /test       <=======\nshm              64M     0   64M   0% /dev/shm\ntmpfs           2.0G   12K  2.0G   1% /run/secrets/kubernetes.io/serviceaccount\ntmpfs           2.0G     0  2.0G   0% /proc/acpi\ntmpfs           2.0G     0  2.0G   0% /proc/scsi\ntmpfs           2.0G     0  2.0G   0% /sys/firmware\n")),(0,r.kt)("p",null,"Another example sharing a volume between containers.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'$ cat morevolumes2.yaml\napiVersion: v1\nkind: Pod\nmetadata: \n  name: morevol2\nspec:\n  containers:\n  - name: centos1\n    image: centos:7\n    command:\n      - sleep\n      - "3600" \n    volumeMounts:\n      - mountPath: /centos\n        name: test\n  - name: centos2\n    image: centos:7\n    command:\n      - sleep\n      - "3600"\n    volumeMounts:\n      - mountPath: /centos2\n        name: test\n  volumes: \n    - name: test\n      emptyDir: {}\n\n\n$ kubectl create -f morevolumes2.yaml\npod/morevol2 created\n\n$ kubectl exec -it morevol2 -c centos1 -- touch /centos/testfile\n$ kubectl exec -it morevol2 -c centos2 -- ls -l /centos2\ntotal 0\n-rw-r--r-- 1 root root 0 Oct  8 06:11 testfile\n')),(0,r.kt)("h4",{id:"using-persistent-volumes"},"Using persistent volumes"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Pod volumes depend on Pods")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"To have storage outlast a pod, the volume should connect to external storage    ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"This can be done from within the pod, but that would require the developer to know about storage specifics")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"To decouple storage requirements from Pod deployment, Persistent Volumes are offered.   ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"PVC(PersistentVolumeClain)")," is used by the user to claim storage in a declaritive way, without worrying about storage specifics.     ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"PVC is a k8s API object that has a spec that defines required storage properties.     ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Based on properties, PVC will reach out to a PV to bind to specific storage     ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"PV is independent to pod.   <===>  PVC <===> Pod (has PVC to access to PV)    ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"PV and PVC has no direct relation.  Those are bound dynamically when necessary.           "))),(0,r.kt)("h4",{id:"setting-up-pods-to-use-pvs"},"Setting up Pods to use PVs"),(0,r.kt)("p",null,"Create a path to user in k8s host.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ minikube ssh\n                         _             _\n            _         _ ( )           ( )\n  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __\n/' _ ` _ `\\| |/' _ `\\| || , <  ( ) ( )| '_`\\  /'__`\\\n| ( ) ( ) || || ( ) || || |\\`\\ | (_) || |_) )(  ___/\n(_) (_) (_)(_)(_) (_)(_)(_) (_)`\\___/'(_,__/'`\\____)\n\n$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\ntmpfs           3.5G  679M  2.8G  20% /\ndevtmpfs        1.9G     0  1.9G   0% /dev\ntmpfs           2.0G     0  2.0G   0% /dev/shm\ntmpfs           2.0G   10M  2.0G   1% /run\ntmpfs           2.0G     0  2.0G   0% /sys/fs/cgroup\ntmpfs           2.0G  8.0K  2.0G   1% /tmp\n/dev/vda1        17G  3.0G   13G  19% /mnt/vda1\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/3804902e40974da784873de8cc87f9663936835fd66342e7d478acb258b57ab5/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/a9d3476fcbcadcf74f5fe1357fe7d650125359ccd051ec10dcfaa7271cd3c91e/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/218a54e89da72c4cd542ff0642d2925ce9588eddb66539ca7b64d96c6541a527/merged\nshm              64M     0   64M   0% /var/lib/docker/containers/11bca17f331e7eac01f2688d539ab7bde4dd2ea1837a581b7a3c96608814a23d/mounts/shm\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/9319c2770817c906dc6c34abcf70cf23a942de54d92496207b9f0e7cbecff392/merged\nshm              64M     0   64M   0% /var/lib/docker/containers/bf7004c93c9e9004f814c8861136e3d45356aa7e5444aa567533d1ce8ce3b494/mounts/shm\nshm              64M     0   64M   0% /var/lib/docker/containers/67274633884f3a7147b4d28902458934c79be094de9aaea988dca4d9bd455265/mounts/shm\nshm              64M     0   64M   0% /var/lib/docker/containers/2cd313fc6db7274f3655b2a9ecb13e9ee6e9e3ed109d0297c8f8dcc572db9c7d/mounts/shm\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/012b4b7b290bada7137b958631b82b3b363aedddf9d166acf7b8564f3e1f2980/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/68a47b0ea0762377dd7041d333a3fd24fd8b69d9905f58369d16af4fa834d822/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/a296b3f42291056f21dd01324318b6e0ea977ad642104b0d21c12a3bd98fac24/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/afbbc4dc554f04b2c397cdaa234eaa77e5ffe7d1a8137bec1e0c1e589016c3a5/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/530e131a26910f86adde91225019a65769fa5f65851655bfadafe9ab75e2b165/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/d7c775c6eeb2c235b4ec0e398ce88c7f99792e7e5b5ac19dd9c05d50f6ca6661/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/95a6e5438ccebe4a9c70b7a50e000d3d7fe4ba6542a0a2399d77e767320586e5/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/aae81a3b3a0aed9abd14b7beb324ad88370f8b18aed2f7b354687a0d308a1913/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/18766dfec9ef14802cad3dbda57e88265247e7e2f90ed05751a4bdbe2f053ba8/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/1237087f2076189f2dc657de8a33525e96c570d04a2b2cb0b9fcd15ba7941542/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/5a41bfe3d52ef14b86163ead4da4ea57e98d47c1c76c8dcb90f8344e3e59fd05/merged\nshm              64M     0   64M   0% /var/lib/docker/containers/6e0e72b562ce43064e1af0dab240b768e2f43adf1f56795ed8b6bc08ac246778/mounts/shm\nshm              64M     0   64M   0% /var/lib/docker/containers/56a46268fffea50b0a95fd6d444a38423fc6ce98b466fada4cf38dd4621f956b/mounts/shm\nshm              64M     0   64M   0% /var/lib/docker/containers/10171e7249f1fae755595aceed007b88ded4ecb0469954b098473f28f0b776b0/mounts/shm\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/a78e8fb8cd113c658c91f3d23d573c16d35a167cf1374864f080952ffb404c42/merged\nshm              64M     0   64M   0% /var/lib/docker/containers/58b20b522446c622e78ec329671216e6356c5036bf540548338453444b1e2e55/mounts/shm\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/f8c0f947209c52ee12bcbd366841af3a4a2163bf85905e124a8ed5e0ca09bf5c/merged\nshm              64M     0   64M   0% /var/lib/docker/containers/61286fe3865cff187090c9d74943bf56e42893a999a24afec52e969b845a914e/mounts/shm\nshm              64M     0   64M   0% /var/lib/docker/containers/62924c3743876e98a57b6062d2d00b73143368cdb48e7c892243eaffca2abb92/mounts/shm\nshm              64M     0   64M   0% /var/lib/docker/containers/75bab8180811c4a5a52ca65afba3c12b9f45f9716c1851acb2baba7b987de04c/mounts/shm\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/c41c288dc1cf61e622d42c60c7f4cffc936eafaeaf39b8095579ffbb27582560/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/03b099b772e9a08a19ac1cf19a919d7e428ed12737b011f4c28fe56fdcfe4dfb/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/2f80e54cd2fe733cf310e7a74be04b8fa5081d1508812c16943e8077460f1a77/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/1f2f9062c9e540c0d23f16cb6a85aaf8595e2b86f8aed0166f2a2096db7fde47/merged\noverlay          17G  3.0G   13G  19% /var/lib/docker/overlay2/ac2edc3273ed3c914b6e6a20328b19e521773564b896f096906b14368ee07eb0/merged\n$ sudo mkdir /mydata\n$ exit\nlogout\n\n")),(0,r.kt)("p",null,"Create a PV   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'[junsulee@fedora kubernetes]$ cat pv.yaml\nkind: PersistentVolume\napiVersion: v1\nmetadata:\n  name: pv-volume\n  labels:\n      type: local\nspec:\n  capacity:\n    storage: 2Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: "/mydata"\n[junsulee@fedora kubernetes]$ kubectl create -f pv.yaml\npersistentvolume/pv-volume created\n\n$ kubectl get pv\nNAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE\npv-volume   2Gi        RWO            Retain           Available                                   103s\n')),(0,r.kt)("p",null,"Create a PVC.",(0,r.kt)("br",{parentName:"p"}),"\n",(0,r.kt)("strong",{parentName:"p"},"It is going to look for any PV with the same accessMode")," , here ",(0,r.kt)("inlineCode",{parentName:"p"},"ReadWriteOnce")," and bind.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"[junsulee@fedora kubernetes]$ cat pvc.yaml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: pv-claim\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n\n[junsulee@fedora kubernetes]$ kubectl create -f pvc.yaml\npersistentvolumeclaim/pv-claim created\n")),(0,r.kt)("p",null,"PVC is bound to a volume name ",(0,r.kt)("inlineCode",{parentName:"p"},"pvc-xxx")," and that is added checking with ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get pv"),".     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl get pvc\nNAME       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npv-claim   Bound    pvc-d54a5923-e241-43cc-b224-b7725d3b8c01   1Gi        RWO            standard       113s\n[junsulee@fedora kubernetes]$ kubectl get pv\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM              STORAGECLASS   REASON   AGE\npv-volume                                  2Gi        RWO            Retain           Available                                              6m57s\npvc-d54a5923-e241-43cc-b224-b7725d3b8c01   1Gi        RWO            Delete           Bound       default/pv-claim   standard                115s\n")),(0,r.kt)("p",null,"After the pod creation using the pvc, the mount is available.      "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'[junsulee@fedora kubernetes]$ cat pv-pod.yaml\nkind: Pod\napiVersion: v1\nmetadata:\n   name: pv-pod\nspec:\n  volumes:\n    - name: pv-storage\n      persistentVolumeClaim:\n        claimName: pv-claim\n  containers:\n    - name: pv-container\n      image: nginx\n      ports:\n        - containerPort: 80\n          name: "http-server"\n      volumeMounts:\n        - mountPath: "/usr/share/nginx/html"\n          name: pv-storage\n[junsulee@fedora kubernetes]$\n[junsulee@fedora kubernetes]$ kubectl create -f pv-pod.yaml\npod/pv-pod created\n\n[junsulee@fedora kubernetes]$ kubectl get pod\nNAME     READY   STATUS    RESTARTS   AGE\npv-pod   1/1     Running   0          102s\n\n[junsulee@fedora kubernetes]$ kubectl describe pod pv-pod\nName:         pv-pod\nNamespace:    default\nPriority:     0\nNode:         minikube/192.168.39.25\nStart Time:   Sat, 22 Oct 2022 14:03:52 +1100\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           172.17.0.6\nIPs:\n  IP:  172.17.0.6\nContainers:\n  pv-container:\n    Container ID:   docker://08efa2953f164c4a2271b52f8c7331fff37cf4aac6690ccd8ff3467908e159de\n    Image:          nginx\n    Image ID:       docker-pullable://nginx@sha256:5ffb682b98b0362b66754387e86b0cd31a5cb7123e49e7f6f6617690900d20b2\n    Port:           80/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 22 Oct 2022 14:05:10 +1100\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /usr/share/nginx/html from pv-storage (rw)      <=========\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-d6tbm (ro)\nConditions:\n  Type              Status\n  Initialized       True\n  Ready             True\n  ContainersReady   True\n  PodScheduled      True\nVolumes:\n  pv-storage:\n    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)     <=====\n    ClaimName:  pv-claim   <========\n    ReadOnly:   false\n  default-token-d6tbm:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-d6tbm\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  115s  default-scheduler  Successfully assigned default/pv-pod to minikube\n  Normal  Pulling    103s  kubelet            Pulling image "nginx"\n  Normal  Pulled     59s   kubelet            Successfully pulled image "nginx" in 44.215800653s\n  Normal  Created    41s   kubelet            Created container pv-container\n  Normal  Started    35s   kubelet            Started container pv-container\n')),(0,r.kt)("p",null,"Above example is not realistic as we don't put a storage to a specific host only.",(0,r.kt)("br",{parentName:"p"}),"\n","Here are example using a NFS mount path.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'[junsulee@fedora kubernetes]$ cat nfs-pv.yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: nfs-pv\nspec:\n  capacity:\n    storage: 2Gi\n  accessModes:\n    - ReadWriteMany\n  persistentVolumeReclaimPolicy: Retain\n  nfs:\n    path: /data\n    server: 192.168.99.1\n    readOnly: false\n\n[junsulee@fedora kubernetes]$ cat nfs-pvc.yaml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: nfs-pv-claim\nspec:\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 100Mi\n\n[junsulee@fedora kubernetes]$ cat nfs-pv-pod.yaml\nkind: Pod\napiVersion: v1\nmetadata:\n   name: nfs-pv-pod\nspec:\n  volumes:\n    - name: nfs-pv\n      persistentVolumeClaim:\n        claimName: nfs-pv-claim\n  containers:\n    - name: nfs-client1\n      image: centos:latest\n      command:\n        - sleep\n        - "3600"\n      volumeMounts:\n        - mountPath: "/nfsshare"\n          name: nfs-pv\n    - name: nfs-client2\n      image: centos:latest\n      command:\n        - sleep\n        - "3600"\n      volumeMounts:\n        - mountPath: "/nfsshare"\n          name: nfs-pv\n')),(0,r.kt)("h4",{id:"dynamic-provisioning"},"Dynamic provisioning"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"PVs can be created manually or dynamically provisioned.   "),(0,r.kt)("li",{parentName:"ul"},"To dynamically provision a PV, a StrageClass must be referred to in the PVC     "),(0,r.kt)("li",{parentName:"ul"},"Storage classes are using classes that are defined by the administrator    "),(0,r.kt)("li",{parentName:"ul"},"Storage classes are also using provisioners that connect to a specific storage type    "),(0,r.kt)("li",{parentName:"ul"},"A default storage class can be used, alternatively storage classes can be defined manually       "),(0,r.kt)("li",{parentName:"ul"},"A default StorageClass can be used to always specify a storage type so that it doesn't have to be defined in the PVC spec anymore.   "),(0,r.kt)("li",{parentName:"ul"},"You'll find Default StorageClasses in specific Managed K8s environment, such as AKS.         "),(0,r.kt)("li",{parentName:"ul"},"Custom StorageClass is used to define a StorageClass resource that binds to specific storage.     ")),(0,r.kt)("h4",{id:"using-configmaps"},"Using ConfigMaps"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Separate configuration from code"),(0,r.kt)("li",{parentName:"ul"},"ConfigMaps are clear-text, Secrets are base64 encoded"),(0,r.kt)("li",{parentName:"ul"},"Different types can be used : Files, Directories, Literals  "),(0,r.kt)("li",{parentName:"ul"},"No matter which type is used, all the associated data is stored in the ConfigMap or Secret object"),(0,r.kt)("li",{parentName:"ul"},"Secrets are mainly used to push variables.    ")),(0,r.kt)("p",null,"Create a ConfigMap.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"[junsulee@fedora kubernetes]$ cat nginx-custom-config.conf\nserver {\n    listen       8888;\n    server_name  localhost;\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n}\n[junsulee@fedora kubernetes]$ kubectl create cm nginx-cm --from-file nginx-custom-config.conf\nconfigmap/nginx-cm created\n")),(0,r.kt)("p",null,"In ",(0,r.kt)("inlineCode",{parentName:"p"},"data")," section, the content is available.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'[junsulee@fedora kubernetes]$ kubectl get cm nginx-cm -o yaml\napiVersion: v1\ndata:\n  nginx-custom-config.conf: |\n    server {\n        listen       8888;\n        server_name  localhost;\n        location / {\n            root   /usr/share/nginx/html;\n            index  index.html index.htm;\n        }\n    }\nkind: ConfigMap\nmetadata:\n  creationTimestamp: "2022-10-22T03:41:32Z"\n  name: nginx-cm\n  namespace: default\n  resourceVersion: "62148"\n  uid: fba3b2f1-b659-4284-bc2a-0ddad88e2fc2\n\n')),(0,r.kt)("p",null,"Create a pod using the ConfigMap.",(0,r.kt)("br",{parentName:"p"}),"\n","It is mounted as volumes.",(0,r.kt)("br",{parentName:"p"}),"\n","It mounts the path ",(0,r.kt)("inlineCode",{parentName:"p"},"/etc/nginx/conf.d")," with ",(0,r.kt)("inlineCode",{parentName:"p"},"conf")," volume and create ",(0,r.kt)("inlineCode",{parentName:"p"},"default.conf")," file under the path using the content of the ConfigMap ",(0,r.kt)("inlineCode",{parentName:"p"},"nginx-custom-config.conf"),".     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"[junsulee@fedora kubernetes]$ cat nginx-cm.yml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-cm\n  labels:\n    role: web\nspec:\n  containers:\n  - name: nginx-cm\n    image: nginx\n    volumeMounts:\n    - name: conf\n      mountPath: /etc/nginx/conf.d\n  volumes:\n  - name: conf\n    configMap:\n      name: nginx-cm\n      items:\n      - key: nginx-custom-config.conf\n        path: default.conf\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl create -f nginx-cm.yml\npod/nginx-cm created\n\n[junsulee@fedora kubernetes]$ kubectl exec -it nginx-cm -- cat /etc/nginx/conf.d/default.conf\nserver {\n    listen       8888;\n    server_name  localhost;\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n}\n")),(0,r.kt)("h4",{id:"using-secret"},"Using Secret"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"K8s automatically creates Secrets that contains credentials for accessing the API, and automatically modifies the Pods to use this type of Secret   ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"kubectl describe pod <podname>")," and look for the mount section to see them.   ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"While creating a secret, the next value must be base64 encoded")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"You can create a secret. When using ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl create secret")," this is happening automatically.      ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"From Pods, Secrets are used in the way that ConfigMaps are used.   ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Mounted as volumes  ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Imported as variables.    "))),(0,r.kt)("p",null,"Create a secret.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ kubectl create secret generic secretstuff --from-literal=password=password --from-literal=user=linda\nsecret/secretstuff created\n")),(0,r.kt)("p",null,"The information is encoded.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'[junsulee@fedora kubernetes]$ kubectl get secret secretstuff\nNAME          TYPE     DATA   AGE\nsecretstuff   Opaque   2      11m\n[junsulee@fedora kubernetes]$ kubectl get secret secretstuff -o yaml\napiVersion: v1\ndata:\n  password: cGFzc3dvcmQ=\n  user: bGluZGE=\nkind: Secret\nmetadata:\n  creationTimestamp: "2022-10-22T04:20:07Z"\n  name: secretstuff\n  namespace: default\n  resourceVersion: "64064"\n  uid: e88c872d-f0c4-4768-9155-f654b9c5b6dd\ntype: Opaque\n')),(0,r.kt)("p",null,"Create a pod using the secret.   "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'[junsulee@fedora kubernetes]$ cat pod-secret.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: secretbox2\n  namespace: default\nspec:\n  containers:\n  - name: secretbox\n    image: busybox\n    command:\n      - sleep\n      - "3600"\n    volumeMounts:\n    - mountPath: /secretstuff\n      name: secret\n  volumes:\n  - name: secret\n    secret:\n      secretName: secretstuff\n\n\n[junsulee@fedora kubernetes]$ kubectl create -f pod-secret.yaml\npod/secretbox2 created\n\njunsulee@fedora kubernetes]$ kubectl describe pod secretbox2\nName:         secretbox2\nNamespace:    default\nPriority:     0\nNode:         minikube/192.168.39.25\nStart Time:   Sat, 22 Oct 2022 15:39:39 +1100\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           172.17.0.8\nIPs:\n  IP:  172.17.0.8\nContainers:\n  secretbox:\n    Container ID:  docker://0151e632b9a8a44e002ee5757a8dbfd7ecd46b32b96b702c9ff92fbd4a23a158\n    Image:         busybox\n    Image ID:      docker-pullable://busybox@sha256:9810966b5f712084ea05bf28fc8ba2c8fb110baa2531a10e2da52c1efc504698\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sleep\n      3600\n    State:          Running\n      Started:      Sat, 22 Oct 2022 15:40:14 +1100\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /secretstuff from secret (rw)       <=====\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-d6tbm (ro)\nConditions:\n  Type              Status\n  Initialized       True\n  Ready             True\n  ContainersReady   True\n  PodScheduled      True\nVolumes:\n  secret:\n    Type:        Secret (a volume populated by a Secret)    <=====\n    SecretName:  secretstuff\n    Optional:    false\n  default-token-d6tbm:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-d6tbm\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2m1s  default-scheduler  Successfully assigned default/secretbox2 to minikube\n  Normal  Pulling    109s  kubelet            Pulling image "busybox"\n  Normal  Pulled     95s   kubelet            Successfully pulled image "busybox" in 13.683200681s\n  Normal  Created    89s   kubelet            Created container secretbox\n  Normal  Started    86s   kubelet            Started container secretbox\n\n\n[junsulee@fedora kubernetes]$ kubectl get pod secretbox2 -o yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: "2022-10-22T04:39:39Z"\n  name: secretbox2\n  namespace: default\n  resourceVersion: "65060"\n  uid: 23afef33-efab-450a-ab2a-6824672106b0\nspec:\n  containers:\n  - command:\n    - sleep\n    - "3600"\n    image: busybox\n    imagePullPolicy: Always\n    name: secretbox\n    resources: {}\n    terminationMessagePath: /dev/termination-log\n    terminationMessagePolicy: File\n    volumeMounts:\n    - mountPath: /secretstuff      <=====\n      name: secret\n    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n      name: default-token-d6tbm\n      readOnly: true\n  dnsPolicy: ClusterFirst\n  enableServiceLinks: true\n  nodeName: minikube\n  preemptionPolicy: PreemptLowerPriority\n  priority: 0\n  restartPolicy: Always\n  schedulerName: default-scheduler\n  securityContext: {}\n  serviceAccount: default\n  serviceAccountName: default\n  terminationGracePeriodSeconds: 30\n  tolerations:\n  - effect: NoExecute\n    key: node.kubernetes.io/not-ready\n    operator: Exists\n    tolerationSeconds: 300\n  - effect: NoExecute\n    key: node.kubernetes.io/unreachable\n    operator: Exists\n    tolerationSeconds: 300\n  volumes:\n  - name: secret      <======\n    secret:\n      defaultMode: 420\n      secretName: secretstuff\n  - name: default-token-d6tbm\n    secret:\n      defaultMode: 420\n      secretName: default-token-d6tbm\nstatus:\n  conditions:\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T04:39:39Z"\n    status: "True"\n    type: Initialized\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T04:40:14Z"\n    status: "True"\n    type: Ready\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T04:40:14Z"\n    status: "True"\n    type: ContainersReady\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T04:39:39Z"\n    status: "True"\n    type: PodScheduled\n  containerStatuses:\n  - containerID: docker://0151e632b9a8a44e002ee5757a8dbfd7ecd46b32b96b702c9ff92fbd4a23a158\n    image: busybox:latest\n    imageID: docker-pullable://busybox@sha256:9810966b5f712084ea05bf28fc8ba2c8fb110baa2531a10e2da52c1efc504698\n    lastState: {}\n    name: secretbox\n    ready: true\n    restartCount: 0\n    started: true\n    state:\n      running:\n        startedAt: "2022-10-22T04:40:14Z"\n  hostIP: 192.168.39.25\n  phase: Running\n  podIP: 172.17.0.8\n  podIPs:\n  - ip: 172.17.0.8\n  qosClass: BestEffort\n  startTime: "2022-10-22T04:39:39Z"\n')),(0,r.kt)("p",null,"Check the file inside of the pod.",(0,r.kt)("br",{parentName:"p"}),"\n","Once deployed, the value is shown as plain text.     "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl exec -it secretbox2 -- /bin/sh\n/ # cat /secretstuff/password\npassword/ #\n/ # cat /secretstuff/user\nlinda/ #\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Another example using environment variable"),"  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'\n[junsulee@fedora kubernetes]$ kubectl create secret generic mysql --from-literal=password=root\nsecret/mysql created\n[junsulee@fedora kubernetes]$ kubectl get secrets mysql -o yaml\napiVersion: v1\ndata:\n  password: cm9vdA==\nkind: Secret\nmetadata:\n  creationTimestamp: "2022-10-22T05:33:48Z"\n  name: mysql\n  namespace: default\n  resourceVersion: "67694"\n  uid: 85635175-793d-43d6-8f98-d228a5ec4d4d\ntype: Opaque\n[junsulee@fedora kubernetes]$ kubectl explain pod.spec.containers.env.valueFrom\nKIND:     Pod\nVERSION:  v1\n\nRESOURCE: valueFrom <Object>\n\nDESCRIPTION:\n     Source for the environment variable\'s value. Cannot be used if value is not\n     empty.\n\n     EnvVarSource represents a source for the value of an EnvVar.\n\nFIELDS:\n   configMapKeyRef  <Object>\n     Selects a key of a ConfigMap.\n\n   fieldRef <Object>\n     Selects a field of the pod: supports metadata.name, metadata.namespace,\n     `metadata.labels[\'<KEY>\']`, `metadata.annotations[\'<KEY>\']`, spec.nodeName,\n     spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\n\n   resourceFieldRef <Object>\n     Selects a resource of the container: only resources limits and requests\n     (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu,\n     requests.memory and requests.ephemeral-storage) are currently supported.\n\n   secretKeyRef <Object>\n     Selects a key of a secret in the pod\'s namespace\n\n[junsulee@fedora kubernetes]$ cat pod-secret-as-var.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: mymysql\n  namespace: default\nspec:\n  containers:\n  - name: mysql\n    image: mysql:latest\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: mysql\n          key: password\n\n\n[junsulee@fedora kubernetes]$ kubectl create -f pod-secret-as-var.yaml\npod/mymysql created\n[junsulee@fedora kubernetes]$ kubectl describe pod mymysql\nName:         mymysql\nNamespace:    default\nPriority:     0\nNode:         minikube/192.168.39.25\nStart Time:   Sat, 22 Oct 2022 16:37:21 +1100\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Pending\nIP:\nIPs:          <none>\nContainers:\n  mysql:\n    Container ID:\n    Image:          mysql:latest\n    Image ID:\n    Port:           <none>\n    Host Port:      <none>\n    State:          Waiting\n      Reason:       ContainerCreating\n    Ready:          False\n    Restart Count:  0\n    Environment:\n      MYSQL_ROOT_PASSWORD:  <set to the key \'password\' in secret \'mysql\'>  Optional: false\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-d6tbm (ro)\nConditions:\n  Type              Status\n  Initialized       True\n  Ready             False\n  ContainersReady   False\n  PodScheduled      True\nVolumes:\n  default-token-d6tbm:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-d6tbm\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  90s   default-scheduler  Successfully assigned default/mymysql to minikube\n  Normal  Pulling    76s   kubelet            Pulling image "mysql:latest"\n[junsulee@fedora kubernetes]$\n[junsulee@fedora kubernetes]$ kubectl get pod mymysql -o yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: "2022-10-22T05:37:21Z"\n  name: mymysql\n  namespace: default\n  resourceVersion: "67874"\n  uid: ea09c906-4347-4eb7-a617-837c34ffb530\nspec:\n  containers:\n  - env:\n    - name: MYSQL_ROOT_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          key: password\n          name: mysql\n    image: mysql:latest\n    imagePullPolicy: Always\n    name: mysql\n    resources: {}\n    terminationMessagePath: /dev/termination-log\n    terminationMessagePolicy: File\n    volumeMounts:\n    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n      name: default-token-d6tbm\n      readOnly: true\n  dnsPolicy: ClusterFirst\n  enableServiceLinks: true\n  nodeName: minikube\n  preemptionPolicy: PreemptLowerPriority\n  priority: 0\n  restartPolicy: Always\n  schedulerName: default-scheduler\n  securityContext: {}\n  serviceAccount: default\n  serviceAccountName: default\n  terminationGracePeriodSeconds: 30\n  tolerations:\n  - effect: NoExecute\n    key: node.kubernetes.io/not-ready\n    operator: Exists\n    tolerationSeconds: 300\n  - effect: NoExecute\n    key: node.kubernetes.io/unreachable\n    operator: Exists\n    tolerationSeconds: 300\n  volumes:\n  - name: default-token-d6tbm\n    secret:\n      defaultMode: 420\n      secretName: default-token-d6tbm\nstatus:\n  conditions:\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T05:37:21Z"\n    status: "True"\n    type: Initialized\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T05:37:21Z"\n    message: \'containers with unready status: [mysql]\'\n    reason: ContainersNotReady\n    status: "False"\n    type: Ready\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T05:37:21Z"\n    message: \'containers with unready status: [mysql]\'\n    reason: ContainersNotReady\n    status: "False"\n    type: ContainersReady\n  - lastProbeTime: null\n    lastTransitionTime: "2022-10-22T05:37:21Z"\n    status: "True"\n    type: PodScheduled\n  containerStatuses:\n  - image: mysql:latest\n    imageID: ""\n    lastState: {}\n    name: mysql\n    ready: false\n    restartCount: 0\n    started: false\n    state:\n      waiting:\n        reason: ContainerCreating\n  hostIP: 192.168.39.25\n  phase: Pending\n  qosClass: BestEffort\n  startTime: "2022-10-22T05:37:21Z"\n')),(0,r.kt)("p",null,"Environment variable is set in the pod.    "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[junsulee@fedora kubernetes]$ kubectl exec -it mymysql -- /bin/bash\nbash-4.4# env |grep MYSQL_ROOT_PASSWORD\nMYSQL_ROOT_PASSWORD=root\n")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"#Contents"},"Go to content")),(0,r.kt)("h2",{id:"test2"},"test2"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"#Contents"},"Go to content")))}c.isMDXComponent=!0}}]);